{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steam Data Cleaning\n",
    "\n",
    "*This forms part of a larger series of posts for my [blog](http://nik-davis.github.io) on downloading, processing and analysing data from the steam store. [See all posts here](http://nik-davis.github.io/tag/steam).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "Software versions": [
        {
         "module": "Python",
         "version": "3.7.3 64bit [MSC v.1900 64 bit (AMD64)]"
        },
        {
         "module": "IPython",
         "version": "7.5.0"
        },
        {
         "module": "OS",
         "version": "Windows 10 10.0.18362 SP0"
        },
        {
         "module": "numpy",
         "version": "1.16.3"
        },
        {
         "module": "pandas",
         "version": "0.24.2"
        }
       ]
      },
      "text/html": [
       "<table><tr><th>Software</th><th>Version</th></tr><tr><td>Python</td><td>3.7.3 64bit [MSC v.1900 64 bit (AMD64)]</td></tr><tr><td>IPython</td><td>7.5.0</td></tr><tr><td>OS</td><td>Windows 10 10.0.18362 SP0</td></tr><tr><td>numpy</td><td>1.16.3</td></tr><tr><td>pandas</td><td>0.24.2</td></tr><tr><td colspan='2'>Tue Jun 11 13:07:43 2019 GMT Summer Time</td></tr></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{|l|l|}\\hline\n",
       "{\\bf Software} & {\\bf Version} \\\\ \\hline\\hline\n",
       "Python & 3.7.3 64bit [MSC v.1900 64 bit (AMD64)] \\\\ \\hline\n",
       "IPython & 7.5.0 \\\\ \\hline\n",
       "OS & Windows 10 10.0.18362 SP0 \\\\ \\hline\n",
       "numpy & 1.16.3 \\\\ \\hline\n",
       "pandas & 0.24.2 \\\\ \\hline\n",
       "\\hline \\multicolumn{2}{|l|}{Tue Jun 11 13:07:43 2019 GMT Summer Time} \\\\ \\hline\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "Software versions\n",
       "Python 3.7.3 64bit [MSC v.1900 64 bit (AMD64)]\n",
       "IPython 7.5.0\n",
       "OS Windows 10 10.0.18362 SP0\n",
       "numpy 1.16.3\n",
       "pandas 0.24.2\n",
       "Tue Jun 11 13:07:43 2019 GMT Summer Time"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view software version information\n",
    "\n",
    "# http://raw.github.com/jrjohansson/version_information/master/version_information.py\n",
    "%load_ext version_information\n",
    "# %reload_ext version_information\n",
    "\n",
    "%version_information numpy, pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![steam_logo](https://nik-davis.github.io/images/steam_logo_white.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- PELICAN_BEGIN_SUMMARY -->\n",
    "\n",
    "In the first part of this project, we downloaded and generated data sets from the Steam Store API and SteamSpy API. We now need to take this raw data and prepare it in a process commonly referred to as [data cleaning](https://en.wikipedia.org/wiki/Data_cleansing).\n",
    "\n",
    "Currently the downloaded data is not in a very useful state. Many of the columns contain lengthy strings or missing values, which hinder analysis and are especially crippling to any machine learning techniques we may wish to implement. Data cleaning involves handling missing values, tidying up values, and ensuring data is neatly and consistently formatted.\n",
    "\n",
    "<!-- PELICAN_END_SUMMARY -->\n",
    "\n",
    "Data cleaning is often cited as being the lengthiest part of any project. As such, it will be broken up into sections. We will begin by taking care of the columns in the steam data that are easiest to deal with and outlining a framework for the process. Of course it could all be completed in one go and a lot more concisely, however we'll be stepping through all the reasons for each decision and building the process iteratively.\n",
    "\n",
    "The main aims of this project are to investigate various sales and play-time statistics for games from the Steam store, and see how different features of games affect the success of those games. Keeping this in mind will help inform our decisions about how to handle the various columns in our data set, however it may be a good idea to keep columns which may not seem useful to this particular project in order to provide a robust dataset for future projects.\n",
    "\n",
    "Towards the end of this section, we'll take care of columns that involve exporting data of some kind. Some columns will require much more in-depth processing and cleaning, or provide information that may be a useful topic for another time. We'll clean some of these slightly, then export them separately from the clean dataset.\n",
    "\n",
    "As a separate post, we'll take a look at an optimisation problem, walking through the process of handling one particular column.\n",
    "\n",
    "Once that is complete we will repeat the whole cleaning process for the SteamSpy data and combine the results, finishing with a complete data set ready for analysis.\n",
    "\n",
    "To follow along or perform your own cleaning, the raw data can be found and downloaded on [Kaggle](https://www.kaggle.com/nikdavis/steam-store-raw).\n",
    "\n",
    "## API references:\n",
    "\n",
    "- https://partner.steamgames.com/doc/webapi\n",
    "- https://wiki.teamfortress.com/wiki/User:RJackson/StorefrontAPI\n",
    "- https://steamapi.xpaw.me/#\n",
    "- https://steamspy.com/api.php\n",
    "\n",
    "## Import Libraries and Inspect Data\n",
    "\n",
    "To begin with, we'll import the required libraries and set customisation options, then take a look at the previously downloaded data by reading it into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard library imports\n",
    "from ast import literal_eval\n",
    "import itertools\n",
    "import time\n",
    "import re\n",
    "\n",
    "# third-party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# customisations\n",
    "#pd.set_option(\"max_columns\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 10\n",
      "Columns: 39\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>steam_appid</th>\n",
       "      <th>required_age</th>\n",
       "      <th>is_free</th>\n",
       "      <th>controller_support</th>\n",
       "      <th>dlc</th>\n",
       "      <th>detailed_description</th>\n",
       "      <th>about_the_game</th>\n",
       "      <th>short_description</th>\n",
       "      <th>...</th>\n",
       "      <th>categories</th>\n",
       "      <th>genres</th>\n",
       "      <th>screenshots</th>\n",
       "      <th>movies</th>\n",
       "      <th>recommendations</th>\n",
       "      <th>achievements</th>\n",
       "      <th>release_date</th>\n",
       "      <th>support_info</th>\n",
       "      <th>background</th>\n",
       "      <th>content_descriptors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>game</td>\n",
       "      <td>Counter-Strike</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Play the world's number 1 online action game. ...</td>\n",
       "      <td>Play the world's number 1 online action game. ...</td>\n",
       "      <td>Play the world's number 1 online action game. ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'id': 1, 'description': 'Multi-player'}, {'i...</td>\n",
       "      <td>[{'id': '1', 'description': 'Action'}]</td>\n",
       "      <td>[{'id': 0, 'path_thumbnail': 'https://shared.a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'total': 161366}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'coming_soon': False, 'date': '1 Nov, 2000'}</td>\n",
       "      <td>{'url': 'http://steamcommunity.com/app/10', 'e...</td>\n",
       "      <td>https://store.akamai.steamstatic.com/images/st...</td>\n",
       "      <td>{'ids': [2, 5], 'notes': 'Includes intense vio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>game</td>\n",
       "      <td>Day of Defeat</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Enlist in an intense brand of Axis vs. Allied ...</td>\n",
       "      <td>Enlist in an intense brand of Axis vs. Allied ...</td>\n",
       "      <td>Enlist in an intense brand of Axis vs. Allied ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'id': 1, 'description': 'Multi-player'}, {'i...</td>\n",
       "      <td>[{'id': '1', 'description': 'Action'}]</td>\n",
       "      <td>[{'id': 0, 'path_thumbnail': 'https://shared.a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'total': 4306}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'coming_soon': False, 'date': '1 May, 2003'}</td>\n",
       "      <td>{'url': '', 'email': ''}</td>\n",
       "      <td>https://store.akamai.steamstatic.com/images/st...</td>\n",
       "      <td>{'ids': [2, 5], 'notes': 'This game includes f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>game</td>\n",
       "      <td>Deathmatch Classic</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Enjoy fast-paced multiplayer gaming with Death...</td>\n",
       "      <td>Enjoy fast-paced multiplayer gaming with Death...</td>\n",
       "      <td>Enjoy fast-paced multiplayer gaming with Death...</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'id': 1, 'description': 'Multi-player'}, {'i...</td>\n",
       "      <td>[{'id': '1', 'description': 'Action'}]</td>\n",
       "      <td>[{'id': 0, 'path_thumbnail': 'https://shared.a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'total': 2332}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'coming_soon': False, 'date': '1 Jun, 2001'}</td>\n",
       "      <td>{'url': '', 'email': ''}</td>\n",
       "      <td>https://store.akamai.steamstatic.com/images/st...</td>\n",
       "      <td>{'ids': [], 'notes': None}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>game</td>\n",
       "      <td>Half-Life: Opposing Force</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Return to the Black Mesa Research Facility as ...</td>\n",
       "      <td>Return to the Black Mesa Research Facility as ...</td>\n",
       "      <td>Return to the Black Mesa Research Facility as ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'id': 2, 'description': 'Single-player'}, {'...</td>\n",
       "      <td>[{'id': '1', 'description': 'Action'}]</td>\n",
       "      <td>[{'id': 0, 'path_thumbnail': 'https://shared.a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'total': 22624}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'coming_soon': False, 'date': '1 Nov, 1999'}</td>\n",
       "      <td>{'url': 'https://help.steampowered.com', 'emai...</td>\n",
       "      <td>https://store.akamai.steamstatic.com/images/st...</td>\n",
       "      <td>{'ids': [2, 5], 'notes': 'Half-Life: Opposing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>game</td>\n",
       "      <td>Half-Life</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>full</td>\n",
       "      <td>[323130]</td>\n",
       "      <td>Named Game of the Year by over 50 publications...</td>\n",
       "      <td>Named Game of the Year by over 50 publications...</td>\n",
       "      <td>Named Game of the Year by over 50 publications...</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'id': 2, 'description': 'Single-player'}, {'...</td>\n",
       "      <td>[{'id': '1', 'description': 'Action'}]</td>\n",
       "      <td>[{'id': 0, 'path_thumbnail': 'https://shared.a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'total': 106552}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'coming_soon': False, 'date': '19 Nov, 1998'}</td>\n",
       "      <td>{'url': 'http://steamcommunity.com/app/70', 'e...</td>\n",
       "      <td>https://store.akamai.steamstatic.com/images/st...</td>\n",
       "      <td>{'ids': [2, 5], 'notes': 'Half-Life includes s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                       name  steam_appid  required_age  is_free  \\\n",
       "0  game             Counter-Strike           10             0    False   \n",
       "1  game              Day of Defeat           30             0    False   \n",
       "2  game         Deathmatch Classic           40             0    False   \n",
       "3  game  Half-Life: Opposing Force           50             0    False   \n",
       "4  game                  Half-Life           70             0    False   \n",
       "\n",
       "  controller_support       dlc  \\\n",
       "0                NaN       NaN   \n",
       "1                NaN       NaN   \n",
       "2                NaN       NaN   \n",
       "3                NaN       NaN   \n",
       "4               full  [323130]   \n",
       "\n",
       "                                detailed_description  \\\n",
       "0  Play the world's number 1 online action game. ...   \n",
       "1  Enlist in an intense brand of Axis vs. Allied ...   \n",
       "2  Enjoy fast-paced multiplayer gaming with Death...   \n",
       "3  Return to the Black Mesa Research Facility as ...   \n",
       "4  Named Game of the Year by over 50 publications...   \n",
       "\n",
       "                                      about_the_game  \\\n",
       "0  Play the world's number 1 online action game. ...   \n",
       "1  Enlist in an intense brand of Axis vs. Allied ...   \n",
       "2  Enjoy fast-paced multiplayer gaming with Death...   \n",
       "3  Return to the Black Mesa Research Facility as ...   \n",
       "4  Named Game of the Year by over 50 publications...   \n",
       "\n",
       "                                   short_description  ...  \\\n",
       "0  Play the world's number 1 online action game. ...  ...   \n",
       "1  Enlist in an intense brand of Axis vs. Allied ...  ...   \n",
       "2  Enjoy fast-paced multiplayer gaming with Death...  ...   \n",
       "3  Return to the Black Mesa Research Facility as ...  ...   \n",
       "4  Named Game of the Year by over 50 publications...  ...   \n",
       "\n",
       "                                          categories  \\\n",
       "0  [{'id': 1, 'description': 'Multi-player'}, {'i...   \n",
       "1  [{'id': 1, 'description': 'Multi-player'}, {'i...   \n",
       "2  [{'id': 1, 'description': 'Multi-player'}, {'i...   \n",
       "3  [{'id': 2, 'description': 'Single-player'}, {'...   \n",
       "4  [{'id': 2, 'description': 'Single-player'}, {'...   \n",
       "\n",
       "                                   genres  \\\n",
       "0  [{'id': '1', 'description': 'Action'}]   \n",
       "1  [{'id': '1', 'description': 'Action'}]   \n",
       "2  [{'id': '1', 'description': 'Action'}]   \n",
       "3  [{'id': '1', 'description': 'Action'}]   \n",
       "4  [{'id': '1', 'description': 'Action'}]   \n",
       "\n",
       "                                         screenshots movies  \\\n",
       "0  [{'id': 0, 'path_thumbnail': 'https://shared.a...    NaN   \n",
       "1  [{'id': 0, 'path_thumbnail': 'https://shared.a...    NaN   \n",
       "2  [{'id': 0, 'path_thumbnail': 'https://shared.a...    NaN   \n",
       "3  [{'id': 0, 'path_thumbnail': 'https://shared.a...    NaN   \n",
       "4  [{'id': 0, 'path_thumbnail': 'https://shared.a...    NaN   \n",
       "\n",
       "     recommendations achievements  \\\n",
       "0  {'total': 161366}          NaN   \n",
       "1    {'total': 4306}          NaN   \n",
       "2    {'total': 2332}          NaN   \n",
       "3   {'total': 22624}          NaN   \n",
       "4  {'total': 106552}          NaN   \n",
       "\n",
       "                                     release_date  \\\n",
       "0   {'coming_soon': False, 'date': '1 Nov, 2000'}   \n",
       "1   {'coming_soon': False, 'date': '1 May, 2003'}   \n",
       "2   {'coming_soon': False, 'date': '1 Jun, 2001'}   \n",
       "3   {'coming_soon': False, 'date': '1 Nov, 1999'}   \n",
       "4  {'coming_soon': False, 'date': '19 Nov, 1998'}   \n",
       "\n",
       "                                        support_info  \\\n",
       "0  {'url': 'http://steamcommunity.com/app/10', 'e...   \n",
       "1                           {'url': '', 'email': ''}   \n",
       "2                           {'url': '', 'email': ''}   \n",
       "3  {'url': 'https://help.steampowered.com', 'emai...   \n",
       "4  {'url': 'http://steamcommunity.com/app/70', 'e...   \n",
       "\n",
       "                                          background  \\\n",
       "0  https://store.akamai.steamstatic.com/images/st...   \n",
       "1  https://store.akamai.steamstatic.com/images/st...   \n",
       "2  https://store.akamai.steamstatic.com/images/st...   \n",
       "3  https://store.akamai.steamstatic.com/images/st...   \n",
       "4  https://store.akamai.steamstatic.com/images/st...   \n",
       "\n",
       "                                 content_descriptors  \n",
       "0  {'ids': [2, 5], 'notes': 'Includes intense vio...  \n",
       "1  {'ids': [2, 5], 'notes': 'This game includes f...  \n",
       "2                         {'ids': [], 'notes': None}  \n",
       "3  {'ids': [2, 5], 'notes': 'Half-Life: Opposing ...  \n",
       "4  {'ids': [2, 5], 'notes': 'Half-Life includes s...  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in downloaded data\n",
    "raw_steam_data = pd.read_csv('../data/download/steam_app_data.csv')\n",
    "\n",
    "# print out number of rows and columns\n",
    "print('Rows:', raw_steam_data.shape[0])\n",
    "print('Columns:', raw_steam_data.shape[1])\n",
    "\n",
    "# view first five rows\n",
    "raw_steam_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From a quick inspection of the data, we can see that we have a mixture of numeric and string columns, plenty of missing values, and a number of columns that look to be stored as dictionaries or lists.\n",
    "\n",
    "We can chain the `isnull()` and `sum()` methods to easily see how many missing values we have in each column. Immediately we can see that a number of columns have over 20,000 rows with missing data, and in a data set of roughly 30,000 rows these are unlikely to provide any meaningful information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type                        0\n",
       "name                        0\n",
       "steam_appid                 0\n",
       "required_age                0\n",
       "is_free                     0\n",
       "controller_support          8\n",
       "dlc                         8\n",
       "detailed_description        0\n",
       "about_the_game              0\n",
       "short_description           0\n",
       "fullgame                   10\n",
       "supported_languages         0\n",
       "header_image                0\n",
       "website                     7\n",
       "pc_requirements             0\n",
       "mac_requirements            0\n",
       "linux_requirements          0\n",
       "legal_notice               10\n",
       "drm_notice                 10\n",
       "ext_user_account_notice    10\n",
       "developers                  0\n",
       "publishers                  0\n",
       "demos                      10\n",
       "price_overview              0\n",
       "packages                    0\n",
       "package_groups              0\n",
       "platforms                   0\n",
       "metacritic                  2\n",
       "reviews                    10\n",
       "categories                  0\n",
       "genres                      0\n",
       "screenshots                 0\n",
       "movies                      9\n",
       "recommendations             0\n",
       "achievements                8\n",
       "release_date                0\n",
       "support_info                0\n",
       "background                  0\n",
       "content_descriptors         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_counts = raw_steam_data.isnull().sum()\n",
    "null_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Processing\n",
    "\n",
    "We will most likely have to handle each column individually, so we will write some functions to keep our methodology organised, and help iteratively develop the process.\n",
    "\n",
    "Our first function will remove the columns with more than 50% missing values, taking care of the columns with high null counts. We can do this by running a filter on the dataframe, as seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drop columns with more than 5 missing rows\n",
      "\n",
      "Columns to drop: ['controller_support', 'dlc', 'fullgame', 'website', 'legal_notice', 'drm_notice', 'ext_user_account_notice', 'demos', 'reviews', 'movies', 'achievements']\n"
     ]
    }
   ],
   "source": [
    "threshold = raw_steam_data.shape[0] // 2\n",
    "\n",
    "print('Drop columns with more than {} missing rows'.format(threshold))\n",
    "print()\n",
    "\n",
    "drop_rows = raw_steam_data.columns[null_counts > threshold]\n",
    "\n",
    "print('Columns to drop: {}'.format(list(drop_rows)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then look at the type and name columns, thinning out our data set a little by removing apps without either.\n",
    "\n",
    "In the data collection stage, if no information was returned from an app's API request, only the name and appid was stored. We can easily identify these apps by looking at rows with missing data in the `type` column, as all other apps have a value here. As seen below, these rows contain no other information so we can safely remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows to remove: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>steam_appid</th>\n",
       "      <th>required_age</th>\n",
       "      <th>is_free</th>\n",
       "      <th>controller_support</th>\n",
       "      <th>dlc</th>\n",
       "      <th>detailed_description</th>\n",
       "      <th>about_the_game</th>\n",
       "      <th>short_description</th>\n",
       "      <th>...</th>\n",
       "      <th>categories</th>\n",
       "      <th>genres</th>\n",
       "      <th>screenshots</th>\n",
       "      <th>movies</th>\n",
       "      <th>recommendations</th>\n",
       "      <th>achievements</th>\n",
       "      <th>release_date</th>\n",
       "      <th>support_info</th>\n",
       "      <th>background</th>\n",
       "      <th>content_descriptors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [type, name, steam_appid, required_age, is_free, controller_support, dlc, detailed_description, about_the_game, short_description, fullgame, supported_languages, header_image, website, pc_requirements, mac_requirements, linux_requirements, legal_notice, drm_notice, ext_user_account_notice, developers, publishers, demos, price_overview, packages, package_groups, platforms, metacritic, reviews, categories, genres, screenshots, movies, recommendations, achievements, release_date, support_info, background, content_descriptors]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 39 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Rows to remove:', raw_steam_data[raw_steam_data['type'].isnull()].shape[0])\n",
    "\n",
    "# preview rows with missing type data\n",
    "raw_steam_data[raw_steam_data['type'].isnull()].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the counts of unique values in a column by using the pandas [Series.value_counts](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.value_counts.html) method. By checking the value counts we see that all rows either have a missing value, as noted above, or 'game' in the `type` column.\n",
    "\n",
    "Once the null rows are removed, we'll be able to remove this column as it doesn't provide us with any more useful information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type\n",
       "game    10\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_steam_data['type'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a look now at the name column, we can check for rows which either have a null value or a string containing 'none'. This isn't recognised as a null value but should be treated as such.\n",
    "\n",
    "We achieve this by combining boolean filters using brackets and a vertical bar, `|`, symbolising a logical 'or'.\n",
    "\n",
    "There are only four rows which match these criteria, and they appear to be missing a lot of data in other columns so we should definitely remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>steam_appid</th>\n",
       "      <th>required_age</th>\n",
       "      <th>is_free</th>\n",
       "      <th>controller_support</th>\n",
       "      <th>dlc</th>\n",
       "      <th>detailed_description</th>\n",
       "      <th>about_the_game</th>\n",
       "      <th>short_description</th>\n",
       "      <th>...</th>\n",
       "      <th>categories</th>\n",
       "      <th>genres</th>\n",
       "      <th>screenshots</th>\n",
       "      <th>movies</th>\n",
       "      <th>recommendations</th>\n",
       "      <th>achievements</th>\n",
       "      <th>release_date</th>\n",
       "      <th>support_info</th>\n",
       "      <th>background</th>\n",
       "      <th>content_descriptors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [type, name, steam_appid, required_age, is_free, controller_support, dlc, detailed_description, about_the_game, short_description, fullgame, supported_languages, header_image, website, pc_requirements, mac_requirements, linux_requirements, legal_notice, drm_notice, ext_user_account_notice, developers, publishers, demos, price_overview, packages, package_groups, platforms, metacritic, reviews, categories, genres, screenshots, movies, recommendations, achievements, release_date, support_info, background, content_descriptors]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 39 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_steam_data[(raw_steam_data['name'].isnull()) | (raw_steam_data['name'] == 'none')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we know for certain that all AppIDs should be unique, any rows with the same ID need to be handled.\n",
    "\n",
    "We can easily view duplicated rows using the [DataFrame.duplicated()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.duplicated.html) method of pandas. We can pass `keep=False` to view all duplicated rows, or leave the defaults (`keep='first'`) to skip over the first row and just show the rest of the duplicates. We can also pass a column label into `subset` if we want to filter by a single column.\n",
    "\n",
    "As we only want to remove the extra rows, we can keep the default behaviour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate rows to remove: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>steam_appid</th>\n",
       "      <th>required_age</th>\n",
       "      <th>is_free</th>\n",
       "      <th>controller_support</th>\n",
       "      <th>dlc</th>\n",
       "      <th>detailed_description</th>\n",
       "      <th>about_the_game</th>\n",
       "      <th>short_description</th>\n",
       "      <th>...</th>\n",
       "      <th>categories</th>\n",
       "      <th>genres</th>\n",
       "      <th>screenshots</th>\n",
       "      <th>movies</th>\n",
       "      <th>recommendations</th>\n",
       "      <th>achievements</th>\n",
       "      <th>release_date</th>\n",
       "      <th>support_info</th>\n",
       "      <th>background</th>\n",
       "      <th>content_descriptors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>game</td>\n",
       "      <td>Counter-Strike: Condition Zero</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>With its extensive Tour of Duty campaign, a ne...</td>\n",
       "      <td>With its extensive Tour of Duty campaign, a ne...</td>\n",
       "      <td>With its extensive Tour of Duty campaign, a ne...</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'id': 2, 'description': 'Single-player'}, {'...</td>\n",
       "      <td>[{'id': '1', 'description': 'Action'}]</td>\n",
       "      <td>[{'id': 0, 'path_thumbnail': 'https://shared.a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'total': 20027}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'coming_soon': False, 'date': '1 Mar, 2004'}</td>\n",
       "      <td>{'url': 'http://steamcommunity.com/app/80', 'e...</td>\n",
       "      <td>https://store.akamai.steamstatic.com/images/st...</td>\n",
       "      <td>{'ids': [2, 5], 'notes': 'This game includes f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                            name  steam_appid  required_age  is_free  \\\n",
       "6  game  Counter-Strike: Condition Zero           80             0    False   \n",
       "\n",
       "  controller_support  dlc                               detailed_description  \\\n",
       "6                NaN  NaN  With its extensive Tour of Duty campaign, a ne...   \n",
       "\n",
       "                                      about_the_game  \\\n",
       "6  With its extensive Tour of Duty campaign, a ne...   \n",
       "\n",
       "                                   short_description  ...  \\\n",
       "6  With its extensive Tour of Duty campaign, a ne...  ...   \n",
       "\n",
       "                                          categories  \\\n",
       "6  [{'id': 2, 'description': 'Single-player'}, {'...   \n",
       "\n",
       "                                   genres  \\\n",
       "6  [{'id': '1', 'description': 'Action'}]   \n",
       "\n",
       "                                         screenshots movies   recommendations  \\\n",
       "6  [{'id': 0, 'path_thumbnail': 'https://shared.a...    NaN  {'total': 20027}   \n",
       "\n",
       "  achievements                                   release_date  \\\n",
       "6          NaN  {'coming_soon': False, 'date': '1 Mar, 2004'}   \n",
       "\n",
       "                                        support_info  \\\n",
       "6  {'url': 'http://steamcommunity.com/app/80', 'e...   \n",
       "\n",
       "                                          background  \\\n",
       "6  https://store.akamai.steamstatic.com/images/st...   \n",
       "\n",
       "                                 content_descriptors  \n",
       "6  {'ids': [2, 5], 'notes': 'This game includes f...  \n",
       "\n",
       "[1 rows x 39 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicate_rows = raw_steam_data[raw_steam_data.duplicated()]\n",
    "\n",
    "print('Duplicate rows to remove:', duplicate_rows.shape[0])\n",
    "\n",
    "duplicate_rows.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're now ready to define functions implementing the filters we just looked at. This allows us to easily make changes in the future if we want to alter how the columns are handled, or want to choose a different cut-off threshold for getting rid of columns, for example. \n",
    "\n",
    "We also define a general purpose `process` function which will run all the processing functions we create on the data set. This will allow us to slowly add to it as we develop more functions and ensure we're cleaning the correct dataframe.\n",
    "\n",
    "Finally we run this function on the raw data, inspecting the first few rows and viewing how many rows and columns have been removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 39)\n",
      "(9, 27)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>steam_appid</th>\n",
       "      <th>required_age</th>\n",
       "      <th>is_free</th>\n",
       "      <th>detailed_description</th>\n",
       "      <th>about_the_game</th>\n",
       "      <th>short_description</th>\n",
       "      <th>supported_languages</th>\n",
       "      <th>header_image</th>\n",
       "      <th>pc_requirements</th>\n",
       "      <th>...</th>\n",
       "      <th>platforms</th>\n",
       "      <th>metacritic</th>\n",
       "      <th>categories</th>\n",
       "      <th>genres</th>\n",
       "      <th>screenshots</th>\n",
       "      <th>recommendations</th>\n",
       "      <th>release_date</th>\n",
       "      <th>support_info</th>\n",
       "      <th>background</th>\n",
       "      <th>content_descriptors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Counter-Strike</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Play the world's number 1 online action game. ...</td>\n",
       "      <td>Play the world's number 1 online action game. ...</td>\n",
       "      <td>Play the world's number 1 online action game. ...</td>\n",
       "      <td>English&lt;strong&gt;*&lt;/strong&gt;, French&lt;strong&gt;*&lt;/st...</td>\n",
       "      <td>https://shared.akamai.steamstatic.com/store_it...</td>\n",
       "      <td>{'minimum': '\\n\\t\\t\\t&lt;p&gt;&lt;strong&gt;Minimum:&lt;/stro...</td>\n",
       "      <td>...</td>\n",
       "      <td>{'windows': True, 'mac': True, 'linux': True}</td>\n",
       "      <td>{'score': 88, 'url': 'https://www.metacritic.c...</td>\n",
       "      <td>[{'id': 1, 'description': 'Multi-player'}, {'i...</td>\n",
       "      <td>[{'id': '1', 'description': 'Action'}]</td>\n",
       "      <td>[{'id': 0, 'path_thumbnail': 'https://shared.a...</td>\n",
       "      <td>{'total': 161366}</td>\n",
       "      <td>{'coming_soon': False, 'date': '1 Nov, 2000'}</td>\n",
       "      <td>{'url': 'http://steamcommunity.com/app/10', 'e...</td>\n",
       "      <td>https://store.akamai.steamstatic.com/images/st...</td>\n",
       "      <td>{'ids': [2, 5], 'notes': 'Includes intense vio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Day of Defeat</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Enlist in an intense brand of Axis vs. Allied ...</td>\n",
       "      <td>Enlist in an intense brand of Axis vs. Allied ...</td>\n",
       "      <td>Enlist in an intense brand of Axis vs. Allied ...</td>\n",
       "      <td>English, French, German, Italian, Spanish - Spain</td>\n",
       "      <td>https://shared.akamai.steamstatic.com/store_it...</td>\n",
       "      <td>{'minimum': '\\n\\t\\t\\t&lt;p&gt;&lt;strong&gt;Minimum:&lt;/stro...</td>\n",
       "      <td>...</td>\n",
       "      <td>{'windows': True, 'mac': True, 'linux': True}</td>\n",
       "      <td>{'score': 79, 'url': 'https://www.metacritic.c...</td>\n",
       "      <td>[{'id': 1, 'description': 'Multi-player'}, {'i...</td>\n",
       "      <td>[{'id': '1', 'description': 'Action'}]</td>\n",
       "      <td>[{'id': 0, 'path_thumbnail': 'https://shared.a...</td>\n",
       "      <td>{'total': 4306}</td>\n",
       "      <td>{'coming_soon': False, 'date': '1 May, 2003'}</td>\n",
       "      <td>{'url': '', 'email': ''}</td>\n",
       "      <td>https://store.akamai.steamstatic.com/images/st...</td>\n",
       "      <td>{'ids': [2, 5], 'notes': 'This game includes f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Deathmatch Classic</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Enjoy fast-paced multiplayer gaming with Death...</td>\n",
       "      <td>Enjoy fast-paced multiplayer gaming with Death...</td>\n",
       "      <td>Enjoy fast-paced multiplayer gaming with Death...</td>\n",
       "      <td>English, French, German, Italian, Spanish - Sp...</td>\n",
       "      <td>https://shared.akamai.steamstatic.com/store_it...</td>\n",
       "      <td>{'minimum': '\\n\\t\\t\\t&lt;p&gt;&lt;strong&gt;Minimum:&lt;/stro...</td>\n",
       "      <td>...</td>\n",
       "      <td>{'windows': True, 'mac': True, 'linux': True}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'id': 1, 'description': 'Multi-player'}, {'i...</td>\n",
       "      <td>[{'id': '1', 'description': 'Action'}]</td>\n",
       "      <td>[{'id': 0, 'path_thumbnail': 'https://shared.a...</td>\n",
       "      <td>{'total': 2332}</td>\n",
       "      <td>{'coming_soon': False, 'date': '1 Jun, 2001'}</td>\n",
       "      <td>{'url': '', 'email': ''}</td>\n",
       "      <td>https://store.akamai.steamstatic.com/images/st...</td>\n",
       "      <td>{'ids': [], 'notes': None}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Half-Life: Opposing Force</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Return to the Black Mesa Research Facility as ...</td>\n",
       "      <td>Return to the Black Mesa Research Facility as ...</td>\n",
       "      <td>Return to the Black Mesa Research Facility as ...</td>\n",
       "      <td>English, French, German, Korean</td>\n",
       "      <td>https://shared.akamai.steamstatic.com/store_it...</td>\n",
       "      <td>{'minimum': '\\n\\t\\t\\t&lt;p&gt;&lt;strong&gt;Minimum:&lt;/stro...</td>\n",
       "      <td>...</td>\n",
       "      <td>{'windows': True, 'mac': True, 'linux': True}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'id': 2, 'description': 'Single-player'}, {'...</td>\n",
       "      <td>[{'id': '1', 'description': 'Action'}]</td>\n",
       "      <td>[{'id': 0, 'path_thumbnail': 'https://shared.a...</td>\n",
       "      <td>{'total': 22624}</td>\n",
       "      <td>{'coming_soon': False, 'date': '1 Nov, 1999'}</td>\n",
       "      <td>{'url': 'https://help.steampowered.com', 'emai...</td>\n",
       "      <td>https://store.akamai.steamstatic.com/images/st...</td>\n",
       "      <td>{'ids': [2, 5], 'notes': 'Half-Life: Opposing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Half-Life</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Named Game of the Year by over 50 publications...</td>\n",
       "      <td>Named Game of the Year by over 50 publications...</td>\n",
       "      <td>Named Game of the Year by over 50 publications...</td>\n",
       "      <td>English&lt;strong&gt;*&lt;/strong&gt;, French&lt;strong&gt;*&lt;/st...</td>\n",
       "      <td>https://shared.akamai.steamstatic.com/store_it...</td>\n",
       "      <td>{'minimum': '\\n\\t\\t\\t&lt;p&gt;&lt;strong&gt;Minimum:&lt;/stro...</td>\n",
       "      <td>...</td>\n",
       "      <td>{'windows': True, 'mac': True, 'linux': True}</td>\n",
       "      <td>{'score': 96, 'url': 'https://www.metacritic.c...</td>\n",
       "      <td>[{'id': 2, 'description': 'Single-player'}, {'...</td>\n",
       "      <td>[{'id': '1', 'description': 'Action'}]</td>\n",
       "      <td>[{'id': 0, 'path_thumbnail': 'https://shared.a...</td>\n",
       "      <td>{'total': 106552}</td>\n",
       "      <td>{'coming_soon': False, 'date': '19 Nov, 1998'}</td>\n",
       "      <td>{'url': 'http://steamcommunity.com/app/70', 'e...</td>\n",
       "      <td>https://store.akamai.steamstatic.com/images/st...</td>\n",
       "      <td>{'ids': [2, 5], 'notes': 'Half-Life includes s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        name  steam_appid  required_age  is_free  \\\n",
       "0             Counter-Strike           10             0    False   \n",
       "1              Day of Defeat           30             0    False   \n",
       "2         Deathmatch Classic           40             0    False   \n",
       "3  Half-Life: Opposing Force           50             0    False   \n",
       "4                  Half-Life           70             0    False   \n",
       "\n",
       "                                detailed_description  \\\n",
       "0  Play the world's number 1 online action game. ...   \n",
       "1  Enlist in an intense brand of Axis vs. Allied ...   \n",
       "2  Enjoy fast-paced multiplayer gaming with Death...   \n",
       "3  Return to the Black Mesa Research Facility as ...   \n",
       "4  Named Game of the Year by over 50 publications...   \n",
       "\n",
       "                                      about_the_game  \\\n",
       "0  Play the world's number 1 online action game. ...   \n",
       "1  Enlist in an intense brand of Axis vs. Allied ...   \n",
       "2  Enjoy fast-paced multiplayer gaming with Death...   \n",
       "3  Return to the Black Mesa Research Facility as ...   \n",
       "4  Named Game of the Year by over 50 publications...   \n",
       "\n",
       "                                   short_description  \\\n",
       "0  Play the world's number 1 online action game. ...   \n",
       "1  Enlist in an intense brand of Axis vs. Allied ...   \n",
       "2  Enjoy fast-paced multiplayer gaming with Death...   \n",
       "3  Return to the Black Mesa Research Facility as ...   \n",
       "4  Named Game of the Year by over 50 publications...   \n",
       "\n",
       "                                 supported_languages  \\\n",
       "0  English<strong>*</strong>, French<strong>*</st...   \n",
       "1  English, French, German, Italian, Spanish - Spain   \n",
       "2  English, French, German, Italian, Spanish - Sp...   \n",
       "3                    English, French, German, Korean   \n",
       "4  English<strong>*</strong>, French<strong>*</st...   \n",
       "\n",
       "                                        header_image  \\\n",
       "0  https://shared.akamai.steamstatic.com/store_it...   \n",
       "1  https://shared.akamai.steamstatic.com/store_it...   \n",
       "2  https://shared.akamai.steamstatic.com/store_it...   \n",
       "3  https://shared.akamai.steamstatic.com/store_it...   \n",
       "4  https://shared.akamai.steamstatic.com/store_it...   \n",
       "\n",
       "                                     pc_requirements  ...  \\\n",
       "0  {'minimum': '\\n\\t\\t\\t<p><strong>Minimum:</stro...  ...   \n",
       "1  {'minimum': '\\n\\t\\t\\t<p><strong>Minimum:</stro...  ...   \n",
       "2  {'minimum': '\\n\\t\\t\\t<p><strong>Minimum:</stro...  ...   \n",
       "3  {'minimum': '\\n\\t\\t\\t<p><strong>Minimum:</stro...  ...   \n",
       "4  {'minimum': '\\n\\t\\t\\t<p><strong>Minimum:</stro...  ...   \n",
       "\n",
       "                                       platforms  \\\n",
       "0  {'windows': True, 'mac': True, 'linux': True}   \n",
       "1  {'windows': True, 'mac': True, 'linux': True}   \n",
       "2  {'windows': True, 'mac': True, 'linux': True}   \n",
       "3  {'windows': True, 'mac': True, 'linux': True}   \n",
       "4  {'windows': True, 'mac': True, 'linux': True}   \n",
       "\n",
       "                                          metacritic  \\\n",
       "0  {'score': 88, 'url': 'https://www.metacritic.c...   \n",
       "1  {'score': 79, 'url': 'https://www.metacritic.c...   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4  {'score': 96, 'url': 'https://www.metacritic.c...   \n",
       "\n",
       "                                          categories  \\\n",
       "0  [{'id': 1, 'description': 'Multi-player'}, {'i...   \n",
       "1  [{'id': 1, 'description': 'Multi-player'}, {'i...   \n",
       "2  [{'id': 1, 'description': 'Multi-player'}, {'i...   \n",
       "3  [{'id': 2, 'description': 'Single-player'}, {'...   \n",
       "4  [{'id': 2, 'description': 'Single-player'}, {'...   \n",
       "\n",
       "                                   genres  \\\n",
       "0  [{'id': '1', 'description': 'Action'}]   \n",
       "1  [{'id': '1', 'description': 'Action'}]   \n",
       "2  [{'id': '1', 'description': 'Action'}]   \n",
       "3  [{'id': '1', 'description': 'Action'}]   \n",
       "4  [{'id': '1', 'description': 'Action'}]   \n",
       "\n",
       "                                         screenshots    recommendations  \\\n",
       "0  [{'id': 0, 'path_thumbnail': 'https://shared.a...  {'total': 161366}   \n",
       "1  [{'id': 0, 'path_thumbnail': 'https://shared.a...    {'total': 4306}   \n",
       "2  [{'id': 0, 'path_thumbnail': 'https://shared.a...    {'total': 2332}   \n",
       "3  [{'id': 0, 'path_thumbnail': 'https://shared.a...   {'total': 22624}   \n",
       "4  [{'id': 0, 'path_thumbnail': 'https://shared.a...  {'total': 106552}   \n",
       "\n",
       "                                     release_date  \\\n",
       "0   {'coming_soon': False, 'date': '1 Nov, 2000'}   \n",
       "1   {'coming_soon': False, 'date': '1 May, 2003'}   \n",
       "2   {'coming_soon': False, 'date': '1 Jun, 2001'}   \n",
       "3   {'coming_soon': False, 'date': '1 Nov, 1999'}   \n",
       "4  {'coming_soon': False, 'date': '19 Nov, 1998'}   \n",
       "\n",
       "                                        support_info  \\\n",
       "0  {'url': 'http://steamcommunity.com/app/10', 'e...   \n",
       "1                           {'url': '', 'email': ''}   \n",
       "2                           {'url': '', 'email': ''}   \n",
       "3  {'url': 'https://help.steampowered.com', 'emai...   \n",
       "4  {'url': 'http://steamcommunity.com/app/70', 'e...   \n",
       "\n",
       "                                          background  \\\n",
       "0  https://store.akamai.steamstatic.com/images/st...   \n",
       "1  https://store.akamai.steamstatic.com/images/st...   \n",
       "2  https://store.akamai.steamstatic.com/images/st...   \n",
       "3  https://store.akamai.steamstatic.com/images/st...   \n",
       "4  https://store.akamai.steamstatic.com/images/st...   \n",
       "\n",
       "                                 content_descriptors  \n",
       "0  {'ids': [2, 5], 'notes': 'Includes intense vio...  \n",
       "1  {'ids': [2, 5], 'notes': 'This game includes f...  \n",
       "2                         {'ids': [], 'notes': None}  \n",
       "3  {'ids': [2, 5], 'notes': 'Half-Life: Opposing ...  \n",
       "4  {'ids': [2, 5], 'notes': 'Half-Life includes s...  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def drop_null_cols(df, thresh=0.5):\n",
    "    \"\"\"Drop columns with more than a certain proportion of missing values (Default 50%).\"\"\"\n",
    "    cutoff_count = len(df) * thresh\n",
    "    \n",
    "    return df.dropna(thresh=cutoff_count, axis=1)\n",
    "\n",
    "\n",
    "def process_name_type(df):\n",
    "    \"\"\"Remove null values in name and type columns, and remove type column.\"\"\"\n",
    "    df = df[df['type'].notnull()]\n",
    "    \n",
    "    df = df[df['name'].notnull()]\n",
    "    df = df[df['name'] != 'none']\n",
    "    \n",
    "    df = df.drop('type', axis=1)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "\n",
    "def process(df):\n",
    "    \"\"\"Process data set. Will eventually contain calls to all functions we write.\"\"\"\n",
    "    \n",
    "    # Copy the input dataframe to avoid accidentally modifying original data\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Remove duplicate rows - all appids should be unique\n",
    "    df = df.drop_duplicates()\n",
    "    \n",
    "    # Remove collumns with more than 50% null values\n",
    "    df = drop_null_cols(df)\n",
    "    \n",
    "    # Process rest of columns\n",
    "    df = process_name_type(df)\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(raw_steam_data.shape)\n",
    "initial_processing = process(raw_steam_data)\n",
    "print(initial_processing.shape)\n",
    "initial_processing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Age\n",
    "\n",
    "Next we'll look at the `required_age` column. By looking at the value counts we can see that values are already stored as integers, and the values range from 0 to 20, with one likely error (1818). There are no missing values in this column, but the vast majority have a value of 0. We'll clean the column anyway, but this probably means it won't be of much use in analysis as there is little variance in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "required_age\n",
       "0    9\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_processing['required_age'].value_counts(dropna=False).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whilst fairly useful in its current state, we may benefit from reducing the number of categories that ages fall into. For example, instead of comparing games rated as 5, 6, 7 or 8, we could compare games rated 5+ or 8+.\n",
    "\n",
    "To decide which categories (or bins) we should use, we will look at the [PEGI age ratings](https://pegi.info/) as this is the system used in the United Kingdom, where we're performing our analysis. Ratings fall into one of five categories (3, 7, 12, 16, 18), defining the minimum age recommended to play a game.\n",
    "\n",
    "Using this to inform our decision, we can use the [pandas.cut](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.cut.html) function to sort our data into each of these categories. Rows with 0 may mean they are unrated, unstated as in missing, or rated as suitable for everyone. Because we can't tell we'll leave these as they are. As the erroneous row (1818) is most likely meant to be rated 18 anyway, we can set the upper bound above this value to catch it inside this category.\n",
    "\n",
    "Below we define a `process_age` function to handle this, and inspect the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "required_age\n",
       "0     9\n",
       "3     0\n",
       "7     0\n",
       "12    0\n",
       "16    0\n",
       "18    0\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_age(df):\n",
    "    \"\"\"Format ratings in age column to be in line with the PEGI Age Ratings system.\"\"\"\n",
    "    # PEGI Age ratings: 3, 7, 12, 16, 18\n",
    "    cut_points = [-1, 0, 3, 7, 12, 16, 2000]\n",
    "    label_values = [0, 3, 7, 12, 16, 18]\n",
    "    \n",
    "    df['required_age'] = pd.cut(df['required_age'], bins=cut_points, labels=label_values)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "age_df = process_age(initial_processing)\n",
    "age_df['required_age'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the Platforms Column\n",
    "\n",
    "Whilst we could look at the next column in the dataframe, `is_free`, it would make sense that this is linked to the `price_overview` column. Ultimately we may wish to combine these columns into one, where free games would have a price of 0. \n",
    "\n",
    "Looking at the `price_overview` column, we can see it is stored in a dictionary-like structure, with multiple keys and values. Handling both of these together might be somewhat trickty, so instead we'll look at a simpler example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    {'currency': 'BRL', 'initial': 2069, 'final': ...\n",
       "1    {'currency': 'BRL', 'initial': 1699, 'final': ...\n",
       "2    {'currency': 'BRL', 'initial': 1699, 'final': ...\n",
       "3    {'currency': 'BRL', 'initial': 1699, 'final': ...\n",
       "4    {'currency': 'BRL', 'initial': 2069, 'final': ...\n",
       "Name: price_overview, dtype: object"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_df['price_overview'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `platforms` column appears to contain a key for each of the main operating systems - windows, mac and linux - and a corresponding boolean value, set to True or False depending on the availability on that platform. This should be a reasonably straighforward place to start. We can separate this data out into three columns - one for each platform - filled with boolean values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    {'windows': True, 'mac': True, 'linux': True}\n",
       "1    {'windows': True, 'mac': True, 'linux': True}\n",
       "2    {'windows': True, 'mac': True, 'linux': True}\n",
       "3    {'windows': True, 'mac': True, 'linux': True}\n",
       "4    {'windows': True, 'mac': True, 'linux': True}\n",
       "Name: platforms, dtype: object"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_df['platforms'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far the cleaning process has been relatively simple, mainly requiring checking for null values and dropping some rows or columns. Already we can see that handling the platforms will be a little more complex.\n",
    "\n",
    "Our first hurdle is getting python to recognise the data in the columns as dictionaries rather than just strings. This will allow us to access the different values separately, without having to do some unnecessarily complicated string formatting. As we can see below, even though the data looks like a dictionary it is in fact stored as a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"{'windows': True, 'mac': True, 'linux': True}\""
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "platforms_first_row = age_df['platforms'].iloc[0]\n",
    "\n",
    "print(type(platforms_first_row))\n",
    "\n",
    "platforms_first_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get around this using the handy [literal_eval](https://docs.python.org/3/library/ast.html#ast.literal_eval) function from the built-in `ast` module. As the name suggests, this will allow us to evaluate the string, and then index into it as a \n",
    "dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "{'windows': True, 'mac': True, 'linux': True}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_first_row = literal_eval(platforms_first_row)\n",
    "\n",
    "print(type(eval_first_row))\n",
    "print(eval_first_row)\n",
    "\n",
    "eval_first_row['windows']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to check for missing values, but fortunately it appears there aren't any in this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_df['platforms'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for formatting the output, let's keep things simple and return a list of supported platforms. Another option would be to create a column for each platform with a corresponding True/False value for each row, something we can keep in mind for the future.\n",
    "\n",
    "We can create the desired list by calling the [str.join()](https://docs.python.org/3/library/stdtypes.html#str.join) method on a string, and passing an iterable into the function. In this case, we can pass the keys of the row, as seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'windows;mac;linux'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create string of keys, joined on a semi-colon\n",
    "';'.join(eval_first_row.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to inspect the value of each row, and only end up with the keys that have a value of `True`, skipping those which are `False`. The example below shows how we can do this using a list comprehension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['windows', 'mac']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'windows;mac'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "platforms = {'windows': True, 'mac': True, 'linux': False}\n",
    "\n",
    "# list comprehension\n",
    "print([x for x in platforms.keys() if platforms[x]])\n",
    "\n",
    "# using list comprehension in join\n",
    "';'.join(x for x in platforms.keys() if platforms[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting this all together, we can use the pandas [Series.apply](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.apply.html) method to process the rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "platforms\n",
       "windows;mac;linux    7\n",
       "windows;linux        2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_platforms(df):\n",
    "    \"\"\"Split platforms column into separate boolean columns for each platform.\"\"\"\n",
    "    # evaluate values in platforms column, so can index into dictionaries\n",
    "    df = df.copy()\n",
    "    \n",
    "    def parse_platforms(x):\n",
    "        \n",
    "        d = literal_eval(x)\n",
    "        \n",
    "        return ';'.join(platform for platform in d.keys() if d[platform])\n",
    "    \n",
    "    df['platforms'] = df['platforms'].apply(parse_platforms)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "platforms_df = process_platforms(age_df)\n",
    "platforms_df['platforms'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Price\n",
    "\n",
    "Now we have built up some intuition around how to deal with data stored as dictionaries, let's return to the `is_free` and `price_overview` columns as we should now be able to handle them.\n",
    "\n",
    "First let's check how many null values there are in `price_overview`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "platforms_df['price_overview'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whilst that looks like a lot, we have to consider the impact that the `is_free` column might be having. Before jumping to conclusions let's check if there any rows with `is_free` marked as True and null values in the `price_overview` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "free_and_null_price = platforms_df[(platforms_df['is_free']) & (platforms_df['price_overview'].isnull())]\n",
    "\n",
    "free_and_null_price.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out this accounts for most of the missing values in the `price_overview` column, meaning we can handle these by setting the final price as 0. This makes intuitive sense - free games wouldn't have a price.\n",
    "\n",
    "This means that there are almost 850 rows which aren't free but have null values in the `price_overview` column. Let's investigate those next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>steam_appid</th>\n",
       "      <th>required_age</th>\n",
       "      <th>is_free</th>\n",
       "      <th>detailed_description</th>\n",
       "      <th>about_the_game</th>\n",
       "      <th>short_description</th>\n",
       "      <th>supported_languages</th>\n",
       "      <th>header_image</th>\n",
       "      <th>pc_requirements</th>\n",
       "      <th>...</th>\n",
       "      <th>platforms</th>\n",
       "      <th>metacritic</th>\n",
       "      <th>categories</th>\n",
       "      <th>genres</th>\n",
       "      <th>screenshots</th>\n",
       "      <th>recommendations</th>\n",
       "      <th>release_date</th>\n",
       "      <th>support_info</th>\n",
       "      <th>background</th>\n",
       "      <th>content_descriptors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [name, steam_appid, required_age, is_free, detailed_description, about_the_game, short_description, supported_languages, header_image, pc_requirements, mac_requirements, linux_requirements, developers, publishers, price_overview, packages, package_groups, platforms, metacritic, categories, genres, screenshots, recommendations, release_date, support_info, background, content_descriptors]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 27 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_free_and_null_price = platforms_df[(platforms_df['is_free'] == False) & (platforms_df['price_overview'].isnull())]\n",
    "\n",
    "not_free_and_null_price.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first few rows contain some big, well-known games which appear to have pretty complete data. It looks like we can rule out data errors, so let's dig a little deeper and see if we can find out what is going on.\n",
    "\n",
    "We'll start by looking at the store pages for some of these titles. The url to an app on the steam website follows this structure:\n",
    "\n",
    "    https://store.steampowered.com/app/[steam_appid]\n",
    "\n",
    "This means we can easily generate these links using our above filter. We'll wrap it up in a function in case we want to use it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_steam_links(df):\n",
    "    \"\"\"Print links to store page for apps in a dataframe.\"\"\"\n",
    "    url_base = \"https://store.steampowered.com/app/\"\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        appid = row['steam_appid']\n",
    "        name = row['name']\n",
    "        \n",
    "        print(name + ':', url_base + str(appid))\n",
    "        \n",
    "\n",
    "print_steam_links(not_free_and_null_price[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For these games we can conclude that:\n",
    "\n",
    "- The Ship: Single Player is a tutorial, and comes as part of The Ship: Murder Party\n",
    "- RollerCoaster Tycoon 3: Platinum has been removed from steam (and another game website: [GOG](https://www.gog.com/))  \n",
    "  - \"A spokesperson for GOG told Eurogamer it pulled the game \"due to expiring licensing rights\", and stressed it'll talk with \"new distribution rights holders\" to bring the game back as soon as possible.\" Source: [Eurogamer](https://www.eurogamer.net/articles/2018-05-09-rollercoaster-tycoon-3-pulled-from-steam-gog)\n",
    "- BioShock has been replaced by BioShock Remastered\n",
    "- Sam & Max 101 is sold as part of a season, and this can be found in the `package_groups` column\n",
    "\n",
    "So we have a couple of options here. We could just drop these rows, we could try to figure out the price based on the `package_groups` column, or we could leave them for now and return to them later. We'll leave them for now, handling the two price columns, then take a look at the packages next. It may also be that some of these rows are removed later in the cleaning process for other reasons.\n",
    "\n",
    "If we want to find rows similar to these and deal with each case individually, we could use the `.str.contains()` method, as seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>steam_appid</th>\n",
       "      <th>required_age</th>\n",
       "      <th>is_free</th>\n",
       "      <th>detailed_description</th>\n",
       "      <th>about_the_game</th>\n",
       "      <th>short_description</th>\n",
       "      <th>supported_languages</th>\n",
       "      <th>header_image</th>\n",
       "      <th>pc_requirements</th>\n",
       "      <th>...</th>\n",
       "      <th>platforms</th>\n",
       "      <th>metacritic</th>\n",
       "      <th>categories</th>\n",
       "      <th>genres</th>\n",
       "      <th>screenshots</th>\n",
       "      <th>recommendations</th>\n",
       "      <th>release_date</th>\n",
       "      <th>support_info</th>\n",
       "      <th>background</th>\n",
       "      <th>content_descriptors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [name, steam_appid, required_age, is_free, detailed_description, about_the_game, short_description, supported_languages, header_image, pc_requirements, mac_requirements, linux_requirements, developers, publishers, price_overview, packages, package_groups, platforms, metacritic, categories, genres, screenshots, recommendations, release_date, support_info, background, content_descriptors]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 27 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "platforms_df[platforms_df['name'].str.contains(\"BioShock™\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to figure out how to process the column.\n",
    "\n",
    "If we take a look at the data for the first row, we can see that there are a variety of formats in which the price is stored. There is a currency, GBP, which is perfect as we are performing our analysis in the UK. Next we have a number of different values for the price, so which one do we use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'currency': 'BRL', 'initial': 2069, 'final': 2069, 'discount_percent': 0, 'initial_formatted': '', 'final_formatted': 'R$ 20,69'}\""
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "platforms_df['price_overview'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we inspect another row, we see that there is an active discount, applying an 80% price reduction to the title. It looks like `initial` contains the normal price before discount, and `final` contains the discounted price. `initial_formatted` and `final_formatted` contain the price formatted and displayed in the currency. We don't have to worry about these last two, as we'll be storing the price as a float (or integer) and if we wanted, we could format it like this when printing.\n",
    "\n",
    "With all this in mind, it looks like we'll be checking the value under the `currency` key, and using the value in the `initial` key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'currency': 'BRL', 'initial': 1699, 'final': 1699, 'discount_percent': 0, 'initial_formatted': '', 'final_formatted': 'R$ 16,99'}\""
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "platforms_df['price_overview'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the preliminary investigation is complete we can begin definining our function. \n",
    "\n",
    "We start by evaluating the strings using `literal_eval` as before, however if there is a null value we return a properly formatted dictionary with -1 for the `initial` value. This will allow us to fill in a value of 0 for free games, then be left with an easily targetable value for the actual null rows.\n",
    "\n",
    "Next we create `currency` and `price` columns from the dictionary in the `price_overview` column. We define an anonymous function on the fly using a [lambda](https://docs.python.org/3/tutorial/controlflow.html?highlight=lambda#lambda-expressions) expression, returning the value in each key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>currency</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Counter-Strike</td>\n",
       "      <td>BRL</td>\n",
       "      <td>2069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Day of Defeat</td>\n",
       "      <td>BRL</td>\n",
       "      <td>1699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Deathmatch Classic</td>\n",
       "      <td>BRL</td>\n",
       "      <td>1699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Half-Life: Opposing Force</td>\n",
       "      <td>BRL</td>\n",
       "      <td>1699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Half-Life</td>\n",
       "      <td>BRL</td>\n",
       "      <td>2069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        name currency  price\n",
       "0             Counter-Strike      BRL   2069\n",
       "1              Day of Defeat      BRL   1699\n",
       "2         Deathmatch Classic      BRL   1699\n",
       "3  Half-Life: Opposing Force      BRL   1699\n",
       "4                  Half-Life      BRL   2069"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_price(df):\n",
    "    df = df.copy()\n",
    "        \n",
    "    def parse_price(x):\n",
    "        if x is not np.nan:\n",
    "            return literal_eval(x)\n",
    "        else:\n",
    "            return {'currency': 'GBP', 'initial': -1}\n",
    "    \n",
    "    # evaluate as dictionary and set to -1 if missing\n",
    "    df['price_overview'] = df['price_overview'].apply(parse_price)\n",
    "    \n",
    "    # Create columns from currency and initial values\n",
    "    df['currency'] = df['price_overview'].apply(lambda x: x['currency'])\n",
    "    df['price'] = df['price_overview'].apply(lambda x: x['initial'])\n",
    "    \n",
    "    # Set price of free games to 0\n",
    "    df.loc[df['is_free'], 'price'] = 0\n",
    "    \n",
    "    return df\n",
    "\n",
    "price_data = process_price(platforms_df)[['name', 'currency', 'price']]\n",
    "price_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're almost finished, but let's check if any games don't have GBP listed as the currency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>currency</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Counter-Strike</td>\n",
       "      <td>BRL</td>\n",
       "      <td>2069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Day of Defeat</td>\n",
       "      <td>BRL</td>\n",
       "      <td>1699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Deathmatch Classic</td>\n",
       "      <td>BRL</td>\n",
       "      <td>1699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Half-Life: Opposing Force</td>\n",
       "      <td>BRL</td>\n",
       "      <td>1699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Half-Life</td>\n",
       "      <td>BRL</td>\n",
       "      <td>2069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Counter-Strike: Condition Zero</td>\n",
       "      <td>BRL</td>\n",
       "      <td>2069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Half-Life: Blue Shift</td>\n",
       "      <td>BRL</td>\n",
       "      <td>1699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Half-Life 2</td>\n",
       "      <td>EUR</td>\n",
       "      <td>975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Counter-Strike: Source</td>\n",
       "      <td>BRL</td>\n",
       "      <td>3299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             name currency  price\n",
       "0                  Counter-Strike      BRL   2069\n",
       "1                   Day of Defeat      BRL   1699\n",
       "2              Deathmatch Classic      BRL   1699\n",
       "3       Half-Life: Opposing Force      BRL   1699\n",
       "4                       Half-Life      BRL   2069\n",
       "5  Counter-Strike: Condition Zero      BRL   2069\n",
       "7           Half-Life: Blue Shift      BRL   1699\n",
       "8                     Half-Life 2      EUR    975\n",
       "9          Counter-Strike: Source      BRL   3299"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_data[price_data['currency'] != 'GBP']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some reason there are four games listed in either USD or EUR. We could use the current exchange rate to try and convert them into GBP, however as there are only four rows it's easier and safer to simply drop them.\n",
    "\n",
    "We can also divide the prices by 100 so they are displayed as floats in pounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [name, price]\n",
       "Index: []"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_price(df):\n",
    "    \"\"\"Process price_overview column into formatted price column.\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    def parse_price(x):\n",
    "        if x is not np.nan:\n",
    "            return literal_eval(x)\n",
    "        else:\n",
    "            return {'currency': 'GBP', 'initial': -1}\n",
    "    \n",
    "    # evaluate as dictionary and set to -1 if missing\n",
    "    df['price_overview'] = df['price_overview'].apply(parse_price)\n",
    "    \n",
    "    # create columns from currency and initial values\n",
    "    df['currency'] = df['price_overview'].apply(lambda x: x['currency'])\n",
    "    df['price'] = df['price_overview'].apply(lambda x: x['initial'])\n",
    "    \n",
    "    # set price of free games to 0\n",
    "    df.loc[df['is_free'], 'price'] = 0\n",
    "    \n",
    "    # remove non-GBP rows\n",
    "    df = df[df['currency'] == 'GBP']\n",
    "    \n",
    "    # change price to display in pounds (only applying to rows with a value greater than 0)\n",
    "    df.loc[df['price'] > 0, 'price'] /= 100\n",
    "    \n",
    "    # remove columns no longer needed\n",
    "    df = df.drop(['is_free', 'currency', 'price_overview'], axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "price_df = process_price(platforms_df)\n",
    "price_df[['name', 'price']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Packages\n",
    "\n",
    "We can now take a look at the `packages` and `package_groups` columns to help decide what to do with rows that are missing price data. We're not incredibly interested in the columns themselves, as they don't appear to provide much new useful information, except which games come with others as part of a bundle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>steam_appid</th>\n",
       "      <th>packages</th>\n",
       "      <th>package_groups</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [steam_appid, packages, package_groups, price]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# temporarily set a pandas option using with and option_context\n",
    "with pd.option_context(\"display.max_colwidth\", 500):\n",
    "    display(price_df[['steam_appid', 'packages', 'package_groups', 'price']].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall we have 846 rows with missing price data, which we previously set to -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(price_df[price_df['price'] == -1].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can split these rows into two categories: those with `package_groups` data and those without.\n",
    "\n",
    "If we take a quick look at the `package_groups` column we see that there appear to be no null values. On closer inspection, we can find that rows without data are actually stored as empty lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null counts: 0\n",
      "Empty list counts: 0\n"
     ]
    }
   ],
   "source": [
    "print('Null counts:', price_df['package_groups'].isnull().sum())\n",
    "print('Empty list counts:', price_df[price_df['package_groups'] == \"[]\"].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a combination of filters, we can find out how many rows have both missing `price` and `package_group` data and investigate. We'll count the rows and print links to some of the store pages and look for patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 0 \n",
      "\n",
      "First few rows:\n",
      "\n",
      "\n",
      "Last few rows:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "missing_price_and_package = price_df[(price_df['price'] == -1) & (price_df['package_groups'] == \"[]\")]\n",
    "\n",
    "print('Number of rows:', missing_price_and_package.shape[0], '\\n')\n",
    "\n",
    "print('First few rows:\\n')\n",
    "print_steam_links(missing_price_and_package[:5])\n",
    "\n",
    "print('\\nLast few rows:\\n')\n",
    "print_steam_links(missing_price_and_package[-10:-5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the games - 799 of 846 - with missing price data fall into the above category. This probably means they can be safely removed.\n",
    "\n",
    "From following the links for the first few rows to the store page, it looks like they are currently unavailable or have been delisted from the store. Looking at the last few rows, it appears most of them haven't yet been released and haven't had a price set. We'll take care of all the unreleased games when we clean the `release_date` column, but we can remove all of these apps here.\n",
    "\n",
    "Let's now take a look at the rows that have missing price data but do have `package_groups` data. We may be interested in keeping these rows and extracting price data from the package data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 0 \n",
      "\n",
      "First few rows:\n",
      "\n",
      "\n",
      "Last few rows:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "missing_price_have_package = price_df.loc[(price_df['price'] == -1) & (price_df['package_groups'] != \"[]\"), ['name', 'steam_appid', 'package_groups', 'price']]\n",
    "\n",
    "print('Number of rows:', missing_price_have_package.shape[0], '\\n')\n",
    "\n",
    "print('First few rows:\\n')\n",
    "print_steam_links(missing_price_have_package[:5])\n",
    "\n",
    "print('\\nLast few rows:\\n')\n",
    "print_steam_links(missing_price_have_package[-10:-5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at a selection of these rows, the games appear to be: supersceded by a newer release or remaster, part of a bigger bundle of games or episodic, or included by purchasing another game. \n",
    "\n",
    "Whilst we could extract prices from the `package_groups` data, the most sensible option seems to be removing these rows. There are only 47 rows this applies to, and any with a newer release will still have the re-release in the data.\n",
    "\n",
    "Since our logic interacts heavily with the price data we will update the `process_price` function rather than creating a new one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>steam_appid</th>\n",
       "      <th>required_age</th>\n",
       "      <th>detailed_description</th>\n",
       "      <th>about_the_game</th>\n",
       "      <th>short_description</th>\n",
       "      <th>supported_languages</th>\n",
       "      <th>header_image</th>\n",
       "      <th>pc_requirements</th>\n",
       "      <th>mac_requirements</th>\n",
       "      <th>...</th>\n",
       "      <th>metacritic</th>\n",
       "      <th>categories</th>\n",
       "      <th>genres</th>\n",
       "      <th>screenshots</th>\n",
       "      <th>recommendations</th>\n",
       "      <th>release_date</th>\n",
       "      <th>support_info</th>\n",
       "      <th>background</th>\n",
       "      <th>content_descriptors</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [name, steam_appid, required_age, detailed_description, about_the_game, short_description, supported_languages, header_image, pc_requirements, mac_requirements, linux_requirements, developers, publishers, platforms, metacritic, categories, genres, screenshots, recommendations, release_date, support_info, background, content_descriptors, price]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 24 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_price(df):\n",
    "    \"\"\"Process price_overview column into formatted price column, and take care of package columns.\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    def parse_price(x):\n",
    "        if x is not np.nan:\n",
    "            return literal_eval(x)\n",
    "        else:\n",
    "            return {'currency': 'GBP', 'initial': -1}\n",
    "    \n",
    "    # evaluate as dictionary and set to -1 if missing\n",
    "    df['price_overview'] = df['price_overview'].apply(parse_price)\n",
    "    \n",
    "    # create columns from currency and initial values\n",
    "    df['currency'] = df['price_overview'].apply(lambda x: x['currency'])\n",
    "    df['price'] = df['price_overview'].apply(lambda x: x['initial'])\n",
    "    \n",
    "    # set price of free games to 0\n",
    "    df.loc[df['is_free'], 'price'] = 0\n",
    "    \n",
    "    # remove non-GBP rows\n",
    "    df = df[df['currency'] == 'GBP']\n",
    "    \n",
    "    # remove rows where price is -1\n",
    "    df = df[df['price'] != -1]\n",
    "    \n",
    "    # change price to display in pounds (can apply to all now -1 rows removed)\n",
    "    df['price'] /= 100\n",
    "    \n",
    "    # remove columns no longer needed\n",
    "    df = df.drop(['is_free', 'currency', 'price_overview', 'packages', 'package_groups'], axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "price_df = process_price(platforms_df)\n",
    "price_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next columns in the data are descriptive columns - `detailed_description`, `about_the_game` and `short_description`. We won't be handling them now, instead returning to them later on when we deal with export columns. These are columns where we will export all or some of the data to a separate csv file as part of the cleaning.\n",
    "\n",
    "## Processing Langauges\n",
    "\n",
    "Beyond that, the next column is `supported_languages`. As we will be performing the analysis for an English company, we will only be interested in games available in English. Whilst we could remove non-english game at this stage, instead we will create a column marking english games with a boolean value - True or False.\n",
    "\n",
    "We begin as usual by looking for rows with null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_df['supported_languages'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a closer look at these apps, it doesn't look like there's anything wrong with them. It may be that the data simply wasn't supplied. As there are only 4 rows affected we will go ahead and remove these from the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>steam_appid</th>\n",
       "      <th>required_age</th>\n",
       "      <th>detailed_description</th>\n",
       "      <th>about_the_game</th>\n",
       "      <th>short_description</th>\n",
       "      <th>supported_languages</th>\n",
       "      <th>header_image</th>\n",
       "      <th>pc_requirements</th>\n",
       "      <th>mac_requirements</th>\n",
       "      <th>...</th>\n",
       "      <th>metacritic</th>\n",
       "      <th>categories</th>\n",
       "      <th>genres</th>\n",
       "      <th>screenshots</th>\n",
       "      <th>recommendations</th>\n",
       "      <th>release_date</th>\n",
       "      <th>support_info</th>\n",
       "      <th>background</th>\n",
       "      <th>content_descriptors</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [name, steam_appid, required_age, detailed_description, about_the_game, short_description, supported_languages, header_image, pc_requirements, mac_requirements, linux_requirements, developers, publishers, platforms, metacritic, categories, genres, screenshots, recommendations, release_date, support_info, background, content_descriptors, price]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 24 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_df[price_df['supported_languages'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll take a look at the structure of the column. By looking at the value for the first row and the values for the most common rows, it looks like languages are stored as a string which can be anything from a comma-separated list of languages to a mix of html and headings. It seems reasonably safe to assume that if the app is in English, the word English will appear somewhere in this string. With this in mind we can simply search the string and return a value based on the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/steam-data/lib/python3.9/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mpandas/_libs/index.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/index.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2606\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2630\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[103], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mprice_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msupported_languages\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m      2\u001b[0m price_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupported_languages\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/steam-data/lib/python3.9/site-packages/pandas/core/series.py:1130\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1132\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[0;32m~/miniconda3/envs/steam-data/lib/python3.9/site-packages/pandas/core/series.py:1246\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1243\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1245\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1246\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1249\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m~/miniconda3/envs/steam-data/lib/python3.9/site-packages/pandas/core/indexes/base.py:3819\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3815\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3816\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3817\u001b[0m     ):\n\u001b[1;32m   3818\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3819\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3820\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3821\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3822\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3823\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "print(price_df['supported_languages'][0])\n",
    "price_df['supported_languages'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like English-only games make up a little over half the rows in our dataset (~16,000), and English plus other languages make up many more. We could create columns for any of the other languages by string searching, but for simplicity we'll focus on just the English ones.\n",
    "\n",
    "Using the Series.apply method once again, we can check if the string 'english' appears in each row. We'll return a 1 if 'english' is found and 0 otherwise. Whilst we could use True/False, a binary 1/0 can be interpreted as a boolean value and saves a little space in the csv file. \n",
    "\n",
    "Inside the lambda function, the variable `x` will take on the value of each row as the expression is evaluated. We apply the `lower()` string method so capitalisation doesn't matter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_language(df):\n",
    "    \"\"\"Process supported_languages column into a boolean 'is english' column.\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # drop rows with missing language data\n",
    "    df = df.dropna(subset=['supported_languages'])\n",
    "    \n",
    "    df['english'] = df['supported_languages'].apply(lambda x: 1 if 'english' in x.lower() else 0)\n",
    "    df = df.drop('supported_languages', axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "language_df = process_language(price_df)\n",
    "language_df[['name', 'english']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving on, we can take a quick look at the results and see that most of the apps support English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_df['english'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Developers and Publishers\n",
    "\n",
    "We'll skip over the next few columns and take a look at the `developers` and `publishers` columns. They will most likely contain similar information so we can look at them together. \n",
    "\n",
    "We'll start by checking the null counts, noticing that while the publishers column doesn't appear to have any null values, if we search for empty lists we see that we have over 200 'hidden' null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Developers null counts:', language_df['developers'].isnull().sum())\n",
    "print('Developers empty list counts:', language_df[language_df['developers'] == \"['']\"].shape[0])\n",
    "\n",
    "print('\\nPublishers null counts:', language_df['publishers'].isnull().sum())\n",
    "print('Publishers empty list counts:', language_df[language_df['publishers'] == \"['']\"].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ultimately we want a data set with no missing values. That means we have a few options for dealing with these two columns:\n",
    "\n",
    "- Remove all rows missing either developer or publisher information\n",
    "- Impute missing information by replacing the missing column with the column we have (i.e. if developers is missing, fill it with the value in publishers)\n",
    "- Fill missing information with 'Unknown' or 'None'\n",
    "\n",
    "We can investigate some of the rows with missing data to help inform our decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_dev = language_df[language_df['developers'].isnull()]\n",
    "\n",
    "print('Total games missing developer:', no_dev.shape[0], '\\n')\n",
    "\n",
    "print_steam_links(no_dev[:5])\n",
    "\n",
    "no_pub = language_df[language_df['publishers'] == \"['']\"]\n",
    "\n",
    "print('\\nTotal games missing publisher:', no_pub.shape[0], '\\n')\n",
    "print_steam_links(no_pub[:5])\n",
    "\n",
    "no_dev_or_pub = language_df[(language_df['developers'].isnull()) & (language_df['publishers'] == \"['']\")]\n",
    "\n",
    "print('\\nTotal games missing developer and publisher:', no_dev_or_pub.shape[0], '\\n')\n",
    "print_steam_links(no_dev_or_pub[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears we are looking at a mix of titles, smaller ones especially, and some of the smaller indie titles may have been self-published. Others simply have wrong or missing data, found by searching for the titles elsewhere. As our priority is creating a clean data set, and there are only a few hundred rows, it will be fine to remove them from the data.\n",
    "\n",
    "Let's take a look at the structure of the data. Below we inspect some rows near the beginning of the dataframe. It looks like both columns are stored as lists which can have one or multiple values. We'll have to evaluate the rows as before, so they are recognised as lists, then index into them accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "language_df[['developers', 'publishers']].iloc[24:28]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have some single values and some multiple, we have to decide how to handle them. Here are some potential solutions:\n",
    "\n",
    " - Create a column for each value in the list (i.e. developer_1, developer_2)\n",
    " - Create a column with the first value in the list and a column with the rest of the values (i.e. developer_1, other_developers)\n",
    " - Create a column with the first value in the list and disregard the rest\n",
    " - Combine all values into one column, simply unpacking the list\n",
    " \n",
    "Let's begin defining our function, and take a look at how many rows have multiple developers or publishers. After evaluating each row, we can find the length of the lists in each row by using the [Series.str.len()](http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.len.html) method. By filtering only rows where the list has more than one element, we can find the number of rows with more than one value in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_developers_and_publishers(df):\n",
    "    # remove rows with missing data\n",
    "    df = df[(df['developers'].notnull()) & (df['publishers'] != \"['']\")].copy()\n",
    "    \n",
    "    for col in ['developers', 'publishers']:\n",
    "        df[col] = df[col].apply(lambda x: literal_eval(x))\n",
    "        \n",
    "        # filter dataframe to rows with lists longer than 1, and store the number of rows\n",
    "        num_rows = df[df[col].str.len() > 1].shape[0]\n",
    "        \n",
    "        print('Rows in {} column with multiple values:'.format(col), num_rows)\n",
    "\n",
    "process_developers_and_publishers(language_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that the vast majority have only one value for these columns. If we went with the first or second solutions above, we'd be left with columns with mostly missing data. We could go with the third option, but the first value in the list isn't necessarily the most important, and this seems unfair if multiple teams were involved.\n",
    "\n",
    "The best way forward seems to be the fourth option - if there are multiple values we combine them into the same column. We'll create a list in this case, calling str.join() as we did before. If we pass a list with only one value, we get a string with just that value. If we pass a list with multiple values, we get a string-separated list as desired. We can see this below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "', '.join(['one item'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "', '.join(['multiple', 'different', 'items'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can't join on a comma as a number of developers and publishers have a comma in their name, a couple of which can be seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_df.loc[language_df['developers'].str.contains(\",\", na=False), ['steam_appid', 'developers', 'publishers']].head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead we can join on a semi-colon (`;`). We have 3 rows which contain a semi-colon in their name, so we'll remove these. We'll be able to identify and split individual developer/publisher names in the future by handling it this way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_df.loc[language_df['developers'].str.contains(\";\", na=False), ['steam_appid', 'developers', 'publishers']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also a small number of columns that have `['NA']` or `['N/A']` for publisher. These are some really well hidden null values, and they didn't actually surface until much later in the original development process. This helps highlight the iterative nature of data cleaning - you may discover errors in rows or data that went previously undiscovered, and have to go back and update or correct them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_df[(language_df['publishers'] == \"['NA']\") | (language_df['publishers'] == \"['N/A']\")].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to finish the function we started. We'll abandon the for loop, as there is not too much repetition, and run it on the data as always."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_developers_and_publishers(df):\n",
    "    \"\"\"Parse columns as semicolon-separated string.\"\"\"\n",
    "    # remove rows with missing data (~ means not)\n",
    "    df = df[(df['developers'].notnull()) & (df['publishers'] != \"['']\")].copy()\n",
    "    df = df[~(df['developers'].str.contains(';')) & ~(df['publishers'].str.contains(';'))]\n",
    "    df = df[(df['publishers'] != \"['NA']\") & (df['publishers'] != \"['N/A']\")]\n",
    "    \n",
    "    # create list for each\n",
    "    df['developer'] = df['developers'].apply(lambda x: ';'.join(literal_eval(x)))\n",
    "    df['publisher'] = df['publishers'].apply(lambda x: ';'.join(literal_eval(x)))\n",
    "\n",
    "    df = df.drop(['developers', 'publishers'], axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "dev_pub_df = process_developers_and_publishers(language_df)\n",
    "dev_pub_df[['name', 'steam_appid', 'developer', 'publisher']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Categories and Genres\n",
    "\n",
    "We'll take a look at the `categories` and `genres` columns next. Below we take a look at the null counts and structure of the data. Both appear to be a list of dictionaries containing an id and description key-value pair. Similar to our handling of developers and publishers, it may be best to extract just the descriptions into a list for now. We could make a list of the IDs, keeping track of the corresponding description externally, but that seems overly complex for our purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Categories:\\n')\n",
    "print('Null values:', dev_pub_df['categories'].isnull().sum())\n",
    "print()\n",
    "print(dev_pub_df['categories'][0])\n",
    "\n",
    "print('\\nGenres:\\n')\n",
    "print('Null values:', dev_pub_df['genres'].isnull().sum())\n",
    "print()\n",
    "print(dev_pub_df['genres'].iloc[0])\n",
    "print(dev_pub_df['genres'].iloc[1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we begin defining a function we'll inspect some of the null rows, then we can decide how to handle them.\n",
    "\n",
    "Using the pandas [DataFrame.sample](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sample.html) method, we can randomly sample a number of rows from the dataset. We set a random_state so the output is the same each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_steam_links(dev_pub_df[dev_pub_df['categories'].isnull()].sample(5, random_state=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the above rows with null categories data are applications or software of some kind, and not actually games. It would definitely be best to remove these, as we are interested in analysing games from the steam store.\n",
    "\n",
    "Below we take a look at rows with missing genres data. There doesn't seem to be anything wrong with these games, and it suggests that genre data simply wasn't supplied. As there are only 37 rows affected, we'll remove these rows to keep our dataset complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_steam_links(dev_pub_df[dev_pub_df['genres'].isnull()].sample(5, random_state=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we did for the developer and publisher columns, we can create an anonymous function and join the results on a semicolon. Inside the function we use a list comprehension to traverse each dictionary and extract the value under the `description` key, as seen below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_category = \"[{'id': 1, 'description': 'Multi-player'}, {'id': 36, 'description': 'Online Multi-Player'}, {'id': 37, 'description': 'Local Multi-Player'}]\"\n",
    "\n",
    "[x['description'] for x in literal_eval(example_category)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then use the apply function again to turn each column into a simple delimited list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_categories_and_genres(df):\n",
    "    df = df.copy()\n",
    "    df = df[(df['categories'].notnull()) & (df['genres'].notnull())]\n",
    "    \n",
    "    for col in ['categories', 'genres']:\n",
    "        df[col] = df[col].apply(lambda x: ';'.join(item['description'] for item in literal_eval(x)))\n",
    "    \n",
    "    return df\n",
    "\n",
    "cat_gen_df = process_categories_and_genres(dev_pub_df)\n",
    "cat_gen_df[['steam_appid', 'categories', 'genres']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Achievements and Content Descriptors\n",
    "\n",
    "The final columns we will take a look at before moving on to export columns are `achievements` and `content_descriptors`. Let's take a look at the null counts for each column and a small sample of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Achievements null counts:', cat_gen_df['achievements'].isnull().sum())\n",
    "print('Content Decsriptors null counts:', cat_gen_df['content_descriptors'].isnull().sum())\n",
    "\n",
    "cat_gen_df[['name', 'achievements', 'content_descriptors']].iloc[8:13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like both columns are stored as dictionaries, with standard formats if no details are provided or exist.\n",
    "\n",
    "Below we take a closer look at a single row from the achievements column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "literal_eval(cat_gen_df['achievements'][9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two keys in the top level of the dictionary: `total` and `highlighted`. The highlighted column looks too specific, being a selection of achievements specific to that game, so we will remove it. It may be worthwhile extracting the `total` value though.\n",
    "\n",
    "Now let's take a look at the `content_descriptors` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_gen_df['content_descriptors'].value_counts().head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Content descriptors contain age-related warnings about the content of a game. They are identified by a numeric ID number, with optional notes supplied. Almost 26,000 rows have an empty list, indicating either no content descriptors or none provided. We already have the `required_age` column, which gives us similar information. Because of this, and because the rows are highly specific to each game, we will drop this column entirely. \n",
    "\n",
    "Let's now define a function, taking a look at the value counts to verify everything went as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def process_achievements_and_descriptors(df):\n",
    "    \"\"\"Parse as total number of achievements.\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    df = df.drop('content_descriptors', axis=1)\n",
    "    \n",
    "    def parse_achievements(x):\n",
    "        if x is np.nan:\n",
    "            # missing data, assume has no achievements\n",
    "            return 0\n",
    "        else:\n",
    "            # else has data, so can extract and return number under total\n",
    "            return literal_eval(x)['total']\n",
    "        \n",
    "    df['achievements'] = df['achievements'].apply(parse_achievements)\n",
    "    \n",
    "    return df\n",
    "\n",
    "achiev_df = process_achievements_and_descriptors(cat_gen_df)\n",
    "achiev_df['achievements'].value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like we were successful. We'll leave this column as it is for now, however we may wish to consider grouping the values together in bins, like we did for the age column. This is a decision we can make during the feature engineering stage of our analysis, and we can decide at that point if it will be more useful.\n",
    "\n",
    "Let's now add these functions into the `process` function and run it on the raw data. This isn't strictly necessary but it will keep things organised and ensure we don't accidentally skip running a function.\n",
    "\n",
    "We'll then inspect everything we've completed so far. As you will see, there is still plenty more left to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(df):\n",
    "    \"\"\"Process data set. Will eventually contain calls to all functions we write.\"\"\"\n",
    "    \n",
    "    # Copy the input dataframe to avoid accidentally modifying original data\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Remove duplicate rows - all appids should be unique\n",
    "    df = df.drop_duplicates()\n",
    "    \n",
    "    # Remove collumns with more than 50% null values\n",
    "    df = drop_null_cols(df)\n",
    "    \n",
    "    # Process columns\n",
    "    df = process_name_type(df)\n",
    "    df = process_age(df)\n",
    "    df = process_platforms(df)\n",
    "    df = process_price(df)\n",
    "    df = process_language(df)\n",
    "    df = process_developers_and_publishers(df)\n",
    "    df = process_categories_and_genres(df)\n",
    "    df = process_achievements_and_descriptors(df)\n",
    "    \n",
    "    return df\n",
    "\n",
    "partially_clean = process(raw_steam_data)\n",
    "partially_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Columns\n",
    "\n",
    "There are a number of columns containing information that is either not useful to the current project or is too complex to be useful for now. We may wish to incorporate them into a future project, but for now we will export the columns to separate files and remove them from the dataset.\n",
    "\n",
    "### Processing Description Columns\n",
    "\n",
    "We have a series of columns with descriptive text about each game: `detailed_description`, `about_the_game` and `short_description`. As the column names imply, these provide information about each game in string format. This is great for humans' understanding, but when it comes to machines is a lot trickier.\n",
    "\n",
    "These columns could be used as the basis for an interesting [recommender system](https://en.wikipedia.org/wiki/Recommender_system) or [sentiment analysis](https://en.wikipedia.org/wiki/Sentiment_analysis) project, however they are not required in our current project. We'll be removing them as they take up large amounts of space, and will only serve to slow down any computation on the data.\n",
    "\n",
    "We'll briefly inspect the columns, in case of anomalies, and export just the description data to a separate file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partially_clean[['detailed_description', 'about_the_game', 'short_description']].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 14 rows with missing data for these columns, and chances are the 14 rows with missing `detailed_description` are the rows with missing `about_the_game` and `short_description` data too. \n",
    "\n",
    "By inspecting the individual rows below, we can see that this is true - all rows with missing data in one description column have missing data in the others as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partially_clean[partially_clean['detailed_description'].isnull()].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, all of these titles are games from 2006 developed and published by PopCap Games. My best guess is that they were developed previously and all added to the Steam store in one go after Valve allowed third-party titles.\n",
    "\n",
    "We'll remove these rows, as well as any with a description of less than 20 characters, like those below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partially_clean[partially_clean['detailed_description'].str.len() <= 20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To handle exporting the data to file, we'll write a reusable function which we can call upon for future columns. We will include the `steam_appid` column as it will allow us to match up these rows with rows in our primary dataset later on, using a merge (like a join in SQL)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_data(df, filename):\n",
    "    \"\"\"Export dataframe to csv file, filename prepended with 'steam_'.\n",
    "    \n",
    "    filename : str without file extension\n",
    "    \"\"\"\n",
    "    filepath = '../data/exports/steam_' + filename + '.csv'\n",
    "    \n",
    "    df.to_csv(filepath, index=False)\n",
    "    \n",
    "    print_name = filename.replace('_', ' ')\n",
    "    print(\"Exported {} to '{}'\".format(print_name, filepath))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now define a function to process and export the description columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_descriptions(df, export=False):\n",
    "    \"\"\"Export descriptions to external csv file then remove these columns.\"\"\"\n",
    "    # remove rows with missing description data\n",
    "    df = df[df['detailed_description'].notnull()].copy()\n",
    "    \n",
    "    # remove rows with unusually small description\n",
    "    df = df[df['detailed_description'].str.len() > 20]\n",
    "    \n",
    "    # by default we don't export, useful if calling function later\n",
    "    if export:\n",
    "        # create dataframe of description columns\n",
    "        description_data = df[['steam_appid', 'detailed_description', 'about_the_game', 'short_description']]\n",
    "        \n",
    "        export_data(description_data, filename='description_data')\n",
    "    \n",
    "    # drop description columns from main dataframe\n",
    "    df = df.drop(['detailed_description', 'about_the_game', 'short_description'], axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "desc_df = process_descriptions(partially_clean, export=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect exported data\n",
    "pd.read_csv('../data/exports/steam_description_data.csv').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing Media Columns\n",
    "\n",
    "Similar to the description columns, we have three columns that contain links to various images: `header_image`, `screenshots` and `background`. Whilst we won't be needing this data in this project, it could open the door to some interesting image analysis in the future. We will treat these columns in almost the same way, exporting the contents to a csv file then removing them from the dataset.\n",
    "\n",
    "Again, let's check for missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_cols = ['header_image', 'screenshots', 'background']\n",
    "\n",
    "for col in image_cols:\n",
    "    print(col+':', desc_df[col].isnull().sum())\n",
    "\n",
    "desc_df[image_cols].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the description columns, it is likely that the 4 rows with no `screenshots` data are the same rows with no `background` data. There are so few that it is probably safe to remove them.\n",
    "\n",
    "Before we make up our made let's inspect the rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_screenshots = desc_df[desc_df['screenshots'].isnull()]\n",
    "\n",
    "print_steam_links(no_screenshots)\n",
    "\n",
    "no_screenshots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we predicted, the rows without screenshots are also the rows without a background. It looks like two are unreleased, and if we'd dealt with the `release_date` column already these would already be removed. One was released recently (5 Jan, 2019), and perhaps didn't have screenshots at the time of downloading, and one simply doesn't have any. As we suspected, it's safe to remove all these rows.\n",
    "\n",
    "There is also a `movies` column with similar data. Whilst having more missing values, presumably for games without videos, it appears to contain names, thumbnails and links to various videos and trailers. It's unlikely we'll need them but we can include them in the export and remove them from our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Movies null values:', desc_df['movies'].isnull().sum())\n",
    "print()\n",
    "\n",
    "desc_df[desc_df['movies'].notnull()]['movies'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now put this all together and define a `process_media` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_media(df, export=False):\n",
    "    \"\"\"Remove media columns from dataframe, optionally exporting them to csv first.\"\"\"\n",
    "    df = df[df['screenshots'].notnull()].copy()\n",
    "    \n",
    "    if export:\n",
    "        media_data = df[['steam_appid', 'header_image', 'screenshots', 'background', 'movies']]\n",
    "        \n",
    "        export_data(media_data, 'media_data')\n",
    "        \n",
    "    df = df.drop(['header_image', 'screenshots', 'background', 'movies'], axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "media_df = process_media(desc_df, export=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# inspect exported data\n",
    "pd.read_csv('../data/exports/steam_media_data.csv').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we move on, we can inspect the memory savings of removing these columns by comparing the output of the [DataFrame.info](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.info.html) method. If we pass `memory_usage=\"deep\"` we get the true memory usage of each DataFrame. Without this, pandas estimates the amount used. This is because of the way python stores object (string) columns under the hood. Essentially python keeps track of a list of pointers which point to the actual strings in memory. It's a bit like if you hid a bunch of items around the house, and kept a list of where everything was. You couldn't tell the total size of everything just by looking at the list, but you could take a rough guess. Only by following the list and inspecting each individual item could you get an exact figure.\n",
    "\n",
    "The blog post '[Why Python Is Slow](https://jakevdp.github.io/blog/2014/05/09/why-python-is-slow/)' goes into more detail, but all we need to be aware of is that by passing the parameter we ensure we get the true value of memory usage. We also pass `verbose=False` to truncate unnecessary output.\n",
    "\n",
    "We can see that already we have shrunk the memory usage from 285 MB to just under 55 MB. This is great because in general, the smaller the memory footprint the faster our code will run in future. And of course, we're not finished yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Before removing data:\\n')\n",
    "achiev_df.info(verbose=False, memory_usage=\"deep\")\n",
    "\n",
    "print('\\nData with descriptions and media removed:\\n')\n",
    "media_df.info(verbose=False, memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Website and Support Info\n",
    "\n",
    "Next we will look at the `website` and `support_info` columns. Seen below, they both contain links to external websites. The website column is simply stored as a string whereas the support info column is stored as a dictionary of `url` and `email`.\n",
    "\n",
    "There are a large number of rows with no website listed, and while there are no null values in the `support_info` column, it looks like many will have empty `url` and `email` values inside the data.\n",
    "\n",
    "For our dataset we'll be dropping both these columns, as they are far too specific to be useful in our analysis. As you may have guessed, we will extract and export this data as we have done before. If not useful, it could be interesting at a later date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('website null counts:', media_df['website'].isnull().sum())\n",
    "print('support_info null counts:', media_df['support_info'].isnull().sum())\n",
    "\n",
    "with pd.option_context(\"display.max_colwidth\", 100): # ensures strings not cut short\n",
    "    display(media_df[['name', 'website', 'support_info']][75:80])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to split the support info into two separate columns. We'll keep all the code that parses the columns inside the export `if` statement, so it only runs if we wish to export to csv. We don't need to worry that the rows with missing website data contain `NaN` whereas the other two columns contain a blank string (`''`) for missing data, as once we have exported to csv they will be represented the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_info(df, export=False):\n",
    "    \"\"\"Drop support information from dataframe, optionally exporting beforehand.\"\"\"\n",
    "    if export:\n",
    "        support_info = df[['steam_appid', 'website', 'support_info']].copy()\n",
    "        \n",
    "        support_info['support_info'] = support_info['support_info'].apply(lambda x: literal_eval(x))\n",
    "        support_info['support_url'] = support_info['support_info'].apply(lambda x: x['url'])\n",
    "        support_info['support_email'] = support_info['support_info'].apply(lambda x: x['email'])\n",
    "        \n",
    "        support_info = support_info.drop('support_info', axis=1)\n",
    "        \n",
    "        # only keep rows with at least one piece of information\n",
    "        support_info = support_info[(support_info['website'].notnull()) | (support_info['support_url'] != '') | (support_info['support_email'] != '')]\n",
    "\n",
    "        export_data(support_info, 'support_info')\n",
    "    \n",
    "    df = df.drop(['website', 'support_info'], axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "info_df = process_info(media_df, export=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect exported file\n",
    "pd.read_csv('../data/exports/steam_support_info.csv').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System Requirements\n",
    "\n",
    "As you may have noticed, there are three columns containing the system specifications required to run each game on each platform. These columns are `pc_requirements`, `mac_requirements`, and `linux_requirements`. As computing power has increased over the years, this information won't be of particular use in this analysis. It could be fascinating to use as a proxy of how computers have developed over the years, so we'll want to export the data, but we won't be keeping it in this dataset.\n",
    "\n",
    "Taking a look at the null counts, it looks like there is data for every row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requirements_cols = ['pc_requirements', 'mac_requirements', 'linux_requirements']\n",
    "\n",
    "print('null counts:\\n')\n",
    "\n",
    "for col in requirements_cols:\n",
    "    print(col+':', info_df[col].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However if we look at the data a little more closely, we see that some rows actually store an empty list. These won't appear as null rows, but once evaluated won't provide any information, so can be treated as null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "info_df[['steam_appid', 'pc_requirements', 'mac_requirements', 'linux_requirements']].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using a simple boolean filter and checking the shape pararater, we can get a count for how many empty lists there are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Empty list counts:\\n')\n",
    "\n",
    "for col in requirements_cols:\n",
    "    print(col+':', info_df[info_df[col] == '[]'].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's over half of the rows for both mac and linux requirements. That probably means that there is not enough data in these two columns to be too useful.\n",
    "\n",
    "It turns out that most games are developed solely for windows, with the growth in mac and linux ports only growing in recent years. Naturally it would make sense that any games that aren't supported on mac or linux would not have corresponding requirements.\n",
    "\n",
    "As we have already cleaned the platforms column, we can check how many rows actually have missing data by comparing rows with empty lists in the requirements column with data in the platform column. If a row has an empty list in the requirements column but the platforms column shows it is supported, it means the data is missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['mac_requirements', 'linux_requirements']:\n",
    "    platform = col.split('_')[0]\n",
    "    print(platform+':', info_df[(info_df[col] == '[]') & (info_df['platforms'].str.contains(platform))].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whilst not an insignificant number, this means that the vast majority of rows are as they should be, and we're not looking at too many data errors.\n",
    "\n",
    "Let's also have a look for missing values in the pc/windows column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('windows:', info_df[(info_df['pc_requirements'] == '[]') & (info_df['platforms'].str.contains('windows'))].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 9 rows have missing system requirements. We can take a look at some of them below, and follow the links to the steam pages to try and discover if anything is amiss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_windows_requirements = info_df[(info_df['pc_requirements'] == '[]') & (info_df['platforms'].str.contains('windows'))]\n",
    "\n",
    "print_steam_links(missing_windows_requirements[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There doesn't appear to be any common issue in these rows - some of the games are quite old but that's about it. It may simply be that no requirements were supplied when the games were added to the steam store.\n",
    "\n",
    "We can assume that a cross-platform game will have similar requirements in terms of hardware for each platform it supports. With this in mind we can focus on the `pc_requirements` column, and use the `platforms` column to tell us which other platforms are supported. \n",
    "\n",
    "Now we will take a look at a couple of rows from the dataset, to observe the structure of the stored data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(info_df['pc_requirements'].iloc[0])\n",
    "display(info_df['pc_requirements'].iloc[2000])\n",
    "display(info_df['pc_requirements'].iloc[15000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is stored as a dictionary, as we've seen before. There is definitely a key for `minimum`, but apart from that it is hard to see at a glance. The strings are full of html formatting, which is presumably parsed to display the information on the website. It also looks like there are different categories like `Processor` and `Memory` for some of the rows.\n",
    "\n",
    "Let's take a stab and cleaning out some of the unnessecary formatting and see if it becomes clearer.\n",
    "\n",
    "By creating a dataframe from a selection of rows, we can easily and quickly make changes using the pandas .str accessor, allowing us to use python string formatting and regular expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_requirements = info_df['pc_requirements'].iloc[[0, 2000, 15000]].copy()\n",
    "\n",
    "view_requirements = (view_requirements\n",
    "                         .str.replace(r'\\\\[rtn]', '')\n",
    "                         .str.replace(r'<[pbr]{1,2}>', ' ')\n",
    "                         .str.replace(r'<[\\/\"=\\w\\s]+>', '')\n",
    "                    )\n",
    "\n",
    "for i, row in view_requirements.iteritems():\n",
    "    display(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now see more clearly the contents and structure of these rows. Some rows have both `Minimum` and `Recommended` requirements inside a `minimum` key, and some have separate `minimum` and `recommended` keys. Some have headings like `Processor:` and `Storage:` before various components, others simply have a list of components. Some state particular speeds for components, like 2 Ghz CPU, others state specific models, like 'Intel Core 2 Duo', amongst this information.\n",
    "\n",
    "It seems like it would be possible to extract invidivual component information from this data, however it would be a lengthy and complex process worthy of another project. With that in mind, it seems best to proceed by slightly cleaning the data before exporting it, but not trying to deal with individual components right now.\n",
    "\n",
    "We'll export the raw data, and split out the data in the `minimum` and `recommended` keys. This will mean lots of rows still have recommended data hidden inside the minimum key, but this will do for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_requirements(df, export=False):\n",
    "    if export:\n",
    "        requirements = df[['steam_appid', 'pc_requirements', 'mac_requirements', 'linux_requirements']].copy()\n",
    "        \n",
    "        # remove rows with missing pc requirements\n",
    "        requirements = requirements[requirements['pc_requirements'] != '[]']\n",
    "        \n",
    "        requirements['requirements_clean'] = (requirements['pc_requirements']\n",
    "                                                  .str.replace(r'\\\\[rtn]', '')\n",
    "                                                  .str.replace(r'<[pbr]{1,2}>', ' ')\n",
    "                                                  .str.replace(r'<[\\/\"=\\w\\s]+>', '')\n",
    "                                             )\n",
    "        \n",
    "        requirements['requirements_clean'] = requirements['requirements_clean'].apply(lambda x: literal_eval(x))\n",
    "        \n",
    "        # split out minimum and recommended into separate columns\n",
    "        requirements['minimum'] = requirements['requirements_clean'].apply(lambda x: x['minimum'].replace('Minimum:', '').strip() if 'minimum' in x.keys() else np.nan)\n",
    "        requirements['recommended'] = requirements['requirements_clean'].apply(lambda x: x['recommended'].replace('Recommended:', '').strip() if 'recommended' in x.keys() else np.nan)\n",
    "        \n",
    "        requirements = requirements.drop('requirements_clean', axis=1)\n",
    "        \n",
    "        export_data(requirements, 'requirements_data')\n",
    "        \n",
    "    df = df.drop(['pc_requirements', 'mac_requirements', 'linux_requirements'], axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "reqs_df = process_requirements(info_df, export=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify export\n",
    "pd.read_csv('../data/exports/steam_requirements_data.csv').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Release Date\n",
    "\n",
    "We're almost finished, and the final column to clean is `release_date`. It provides the opportunity for an interesting exploration of code optimisation, so we'll be walking through the development process in a separate post. For now, we'll just include the complete function to run on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export data for optimisation post\n",
    "reqs_df.to_csv('../data/exports/steam_partially_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_release_date(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    def eval_date(x):\n",
    "        x = literal_eval(x)\n",
    "        if x['coming_soon']:\n",
    "            return '' # return blank string so can drop missing at end\n",
    "        else:\n",
    "            return x['date']\n",
    "    \n",
    "    df['release_date'] = df['release_date'].apply(eval_date)\n",
    "    \n",
    "    def parse_date(x):\n",
    "        if re.search(r'[\\d]{1,2} [A-Za-z]{3}, [\\d]{4}', x):\n",
    "            return x.replace(',', '')\n",
    "        elif re.search(r'[A-Za-z]{3} [\\d]{4}', x):\n",
    "            return '1 ' + x\n",
    "        elif x == '':\n",
    "            return np.nan\n",
    "        else:\n",
    "            # Should be everything, print out anything left just in case\n",
    "            print(x)\n",
    "            \n",
    "    df['release_date'] = df['release_date'].apply(parse_date)\n",
    "    df['release_date'] = pd.to_datetime(df['release_date'], format='%d %b %Y', errors='coerce')\n",
    "    \n",
    "    df = df[df['release_date'].notnull()]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now update the `process` function once more, and run the full cleaning process on the raw dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(df):\n",
    "    \"\"\"Process data set. Will eventually contain calls to all functions we write.\"\"\"\n",
    "    \n",
    "    # Copy the input dataframe to avoid accidentally modifying original data\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Remove duplicate rows - all appids should be unique\n",
    "    df = df.drop_duplicates()\n",
    "    \n",
    "    # Remove collumns with more than 50% null values\n",
    "    df = drop_null_cols(df)\n",
    "    \n",
    "    # Process columns\n",
    "    df = process_name_type(df)\n",
    "    df = process_age(df)\n",
    "    df = process_platforms(df)\n",
    "    df = process_price(df)\n",
    "    df = process_language(df)\n",
    "    df = process_developers_and_publishers(df)\n",
    "    df = process_categories_and_genres(df)\n",
    "    df = process_achievements_and_descriptors(df)  \n",
    "    df = process_release_date(df)\n",
    "    \n",
    "    # Process columns which export data\n",
    "    df = process_descriptions(df, export=True)\n",
    "    df = process_media(df, export=True)\n",
    "    df = process_info(df, export=True)\n",
    "    df = process_requirements(df, export=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "steam_data = process(raw_steam_data)\n",
    "steam_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Steps\n",
    "\n",
    "That just about does is for cleaning the Steam data. Hopefully we have a cleaned dataset ready to be combined with the data downloaded from SteamSpy, once that is cleaned. \n",
    "\n",
    "Before we export the cleaned steam data, we'll check that we have eradicated missing values, and have a look at the memory footprint like we did earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_steam_data.info(verbose=False, memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_data.info(verbose=False, memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like we've taken care of all the null values, and the size of the dataset has been reduced considerably.\n",
    "\n",
    "We'll also check that no unreleased games have slipped through (data was scraped on or before 1st May, 2019)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_data[steam_data['release_date'] > '2019-05-01']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we're happy with our dataframe we are ready to export to file and finish this part of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "steam_data.to_csv('../data/exports/steam_data_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I said at the beginning, data cleaning can be a very lengthy process. We definitely could have taken some shortcuts, and didn't have to go into so much depth, but I think it was interesting and valuable to go through the data as thoroughly as we did. A useful side effect of this is that we're now much more familiar with the data, and this should be incredibly useful when it comes to analysis. One of the most important prerequisites for data analysis is having good data, and the foundation of this is built upon solid data cleaning.\n",
    "\n",
    "Next time we'll take a look at optimising the processing of the `release_date` column, as mentioned, then move onto cleaning the SteamSpy data. Once that is complete we can begin exploring and analysing the data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
